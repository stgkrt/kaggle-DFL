{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DFL benchmark - training\n",
    "This is a simple benchmark script for DFL.  \n",
    "It classifies each frame image in the video into 4 classes（'background','challenge','play','throwin'） \n",
    "It does not use temporal information, so it may not be competitive on its own for this competition, but it could be used as a feature extractor for more advanced models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Sep 15 11:52:47 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:01:00.0  On |                  N/A |\n",
      "| 55%   57C    P5    43W / 350W |    885MiB / 24576MiB |     22%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import gc\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import timm\n",
    "from timm import utils\n",
    "\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, OneCycleLR, CosineAnnealingLR, ReduceLROnPlateau, StepLR, LambdaLR\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import imageio\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "class CFG:\n",
    "    EXP = \"eff_b5_ap_bce_flowimage_1output\"\n",
    "\n",
    "    # model\n",
    "    # model_path = \"swint_large224\" #effnetでやってみる？\n",
    "    # model_path =  \"tf_efficientnet_b7_ap\"\n",
    "    model_path =  \"tf_efficientnet_b5_ap\"\n",
    "    MODEL_SAVE_DIR = f\"/workdir/work/output/{EXP}\"\n",
    "    out_features = 1 # output class play:1 or background:0の分類\n",
    "    inp_channels = 3 #RGB -> 3\n",
    "    dropout = 0\n",
    "    pretrained = True\n",
    "\n",
    "    # train, valid\n",
    "    TRAIN_IMG_DIR = \"/workdir/work/output/train_images_flow\"\n",
    "    TRAIN_CSV = \"/workdir/work/output/saved_train_flowimages.csv\"\n",
    "    random_seed = 42\n",
    "    # batch_size = 8\n",
    "    batch_size = 64\n",
    "    num_workers = 0\n",
    "    n_epoch = 150\n",
    "    early_stopping_rounds = 10\n",
    "\n",
    "    img_height = 224\n",
    "    img_width = 224\n",
    "        \n",
    "    #optimizer\n",
    "    gradient_accumulation_steps = 1\n",
    "    max_grad_norm = 1000\n",
    "    opt_eps = 1e-5\n",
    "    lr = 5e-6\n",
    "    opt_wd_non_norm_bias = 0.01\n",
    "    opt_wd_norm_bias = 0\n",
    "\n",
    "    #scheduler\n",
    "    scheduler_name = \"CosineAnnealingLR\"\n",
    "    T_0 = 5\n",
    "    min_lr = 1e-7\n",
    "    max_lr = 5e-5\n",
    "    T_max = 5\n",
    "\n",
    "    seed = 42\n",
    "\n",
    "    if DEBUG:\n",
    "        n_epoch = 1\n",
    "        TRAIN_FOLD = [0, 1]\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "CFG.device = device\n",
    "print(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# save trained model in this dir\n",
    "if not os.path.exists(CFG.MODEL_SAVE_DIR):\n",
    "    os.makedirs(CFG.MODEL_SAVE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EXP NAME = eff_b5_ap_bce_flowimage_1output\n",
      "Model = tf_efficientnet_b5_ap, (height, width) = (224, 224)\n"
     ]
    }
   ],
   "source": [
    "def init_logger(log_file=f'{CFG.MODEL_SAVE_DIR}/train_{CFG.EXP}.log'):\n",
    "    \"\"\"Output Log.\"\"\"\n",
    "    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "LOGGER = init_logger()\n",
    "LOGGER.info(f\"EXP NAME = {CFG.EXP}\")\n",
    "LOGGER.info(f\"Model = {CFG.model_path}, (height, width) = ({CFG.img_height}, {CFG.img_width})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def seed_torch(seed=0):\n",
    "    \"\"\"Fixed seed value.\"\"\"\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_torch(seed=CFG.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-14T13:46:56.464484Z",
     "iopub.status.busy": "2022-08-14T13:46:56.46364Z",
     "iopub.status.idle": "2022-08-14T13:46:56.562918Z",
     "shell.execute_reply": "2022-08-14T13:46:56.561751Z",
     "shell.execute_reply.started": "2022-08-14T13:46:56.464445Z"
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>frame</th>\n",
       "      <th>event</th>\n",
       "      <th>distance</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1606b0e6_0</td>\n",
       "      <td>5006</td>\n",
       "      <td>background</td>\n",
       "      <td>16.120910</td>\n",
       "      <td>200.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1606b0e6_0</td>\n",
       "      <td>6040</td>\n",
       "      <td>background</td>\n",
       "      <td>107.551291</td>\n",
       "      <td>241.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1606b0e6_0</td>\n",
       "      <td>6114</td>\n",
       "      <td>play</td>\n",
       "      <td>95.963118</td>\n",
       "      <td>244.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1606b0e6_0</td>\n",
       "      <td>6174</td>\n",
       "      <td>background</td>\n",
       "      <td>22.191445</td>\n",
       "      <td>246.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1606b0e6_0</td>\n",
       "      <td>6202</td>\n",
       "      <td>play</td>\n",
       "      <td>29.062033</td>\n",
       "      <td>248.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1817</th>\n",
       "      <td>cfbe2e94_1</td>\n",
       "      <td>88110</td>\n",
       "      <td>play</td>\n",
       "      <td>28.930048</td>\n",
       "      <td>3524.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818</th>\n",
       "      <td>cfbe2e94_1</td>\n",
       "      <td>89033</td>\n",
       "      <td>background</td>\n",
       "      <td>12.604130</td>\n",
       "      <td>3561.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1819</th>\n",
       "      <td>cfbe2e94_1</td>\n",
       "      <td>89066</td>\n",
       "      <td>play</td>\n",
       "      <td>28.153789</td>\n",
       "      <td>3562.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1820</th>\n",
       "      <td>cfbe2e94_1</td>\n",
       "      <td>89312</td>\n",
       "      <td>background</td>\n",
       "      <td>16.033176</td>\n",
       "      <td>3572.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1821</th>\n",
       "      <td>cfbe2e94_1</td>\n",
       "      <td>89358</td>\n",
       "      <td>throwin</td>\n",
       "      <td>30.086424</td>\n",
       "      <td>3574.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1822 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        video_id  frame       event    distance     time\n",
       "0     1606b0e6_0   5006  background   16.120910   200.24\n",
       "1     1606b0e6_0   6040  background  107.551291   241.60\n",
       "2     1606b0e6_0   6114        play   95.963118   244.56\n",
       "3     1606b0e6_0   6174  background   22.191445   246.96\n",
       "4     1606b0e6_0   6202        play   29.062033   248.08\n",
       "...          ...    ...         ...         ...      ...\n",
       "1817  cfbe2e94_1  88110        play   28.930048  3524.40\n",
       "1818  cfbe2e94_1  89033  background   12.604130  3561.32\n",
       "1819  cfbe2e94_1  89066        play   28.153789  3562.64\n",
       "1820  cfbe2e94_1  89312  background   16.033176  3572.48\n",
       "1821  cfbe2e94_1  89358     throwin   30.086424  3574.32\n",
       "\n",
       "[1822 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df = pd.read_csv(CFG.TRAIN_CSV)\n",
    "display(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "event_encoding = {\n",
    "    \"background\" : 0.0,\n",
    "    \"challenge\" : 1.0,\n",
    "    \"play\" : 1.0,\n",
    "    \"throwin\" : 1.0,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class DFLDataset(Dataset):\n",
    "    def __init__(self, video_id, frame, targets, transform=None):\n",
    "        self.video_id = video_id\n",
    "        self.frame = frame\n",
    "        self.targets = targets\n",
    "        # self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = f\"{CFG.TRAIN_IMG_DIR}/{self.video_id[idx]}_{self.frame[idx]:06}.jpg\"\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image, dsize=(CFG.img_height, CFG.img_width))\n",
    "        image = image / 255 # convert to 0-1\n",
    "        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n",
    "        target = np.float32(event_encoding[self.targets[idx]])\n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class DFLNet(nn.Module):\n",
    "    def __init__(self, model_name=CFG.model_path, \n",
    "                 out_features=CFG.out_features, inp_channels=CFG.inp_channels,\n",
    "                 pretrained=CFG.pretrained):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained, in_chans=inp_channels, num_classes=out_features)\n",
    "    \n",
    "    def forward(self, image):\n",
    "        fc = self.model(image)\n",
    "        output = torch.sigmoid(fc)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_parameters = [\n",
    "        {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "            'lr': encoder_lr, 'weight_decay': weight_decay},\n",
    "        {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "            'lr': encoder_lr, 'weight_decay': 0.0},\n",
    "        {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n",
    "            'lr': decoder_lr, 'weight_decay': 0.0}\n",
    "    ]\n",
    "    return optimizer_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def get_scheduler(optimizer):\n",
    "    scheduler = None\n",
    "    if CFG.scheduler_name == 'CosineAnnealingWarmRestarts':\n",
    "        scheduler = CosineAnnealingWarmRestarts(\n",
    "            optimizer,\n",
    "            T_0 = CFG.T_0,\n",
    "            eta_min = CFG.min_lr,\n",
    "            last_epoch=-1\n",
    "        )\n",
    "    elif CFG.scheduler_name == 'OneCycleLR':\n",
    "        scheduler = OneCycleLR(\n",
    "            optimizer,\n",
    "            max_lr = CFG.max_lr,\n",
    "            steps_per_epoch = int( ( (CFG.n_fold-1) * train_df.shape[0]) / (CFG.n_fold * CFG.batch_size) ) + 1,\n",
    "            epochs = CFG.n_epoch,\n",
    "        )\n",
    "\n",
    "    elif CFG.scheduler_name == 'CosineAnnealingLR':\n",
    "        scheduler = CosineAnnealingLR(\n",
    "            optimizer,\n",
    "            T_max = CFG.T_max,\n",
    "            eta_min = CFG.min_lr,\n",
    "            last_epoch = -1\n",
    "        )\n",
    "    \n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def divice_norm_bias(model): \n",
    "    norm_bias_params = []\n",
    "    non_norm_bias_params = []\n",
    "    except_wd_layers = ['norm', '.bias']\n",
    "    for n, p in model.model.named_parameters():\n",
    "        if any([nd in n for nd in except_wd_layers]):\n",
    "            norm_bias_params.append(p)\n",
    "        else:\n",
    "            non_norm_bias_params.append(p)\n",
    "    return norm_bias_params, non_norm_bias_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def train_fn(train_loader, model, criterion, optimizer, epoch, scheduler=None, scaler=None):\n",
    "    model.train()\n",
    "    # stream = tqdm(train_loader)\n",
    "    losses = AverageMeter()\n",
    "    global_step = 0\n",
    "\n",
    "    # for step, (images, targets) in enumerate(stream, start=1):\n",
    "    for step, (images, targets) in enumerate(train_loader):\n",
    "        images = images.to(CFG.device, non_blocking=True)\n",
    "        targets = targets.to(CFG.device, non_blocking=True)\n",
    "        targets = targets.view(-1, 1)\n",
    "        batch_size = targets.size(0) \n",
    "\n",
    "        preds = model(images)\n",
    "        loss = criterion(preds, targets)\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "            loss.backward()\n",
    "        else:\n",
    "            loss.backward()\n",
    "        losses.update(loss.item(), batch_size) \n",
    "\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
    "        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            global_step += 1\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "            # scheduler.step_update(num_updates=step, metric=losses.avg)\n",
    "\n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def valid_fn(val_loader, model, criterion, epoch):\n",
    "    model.eval()\n",
    "    # stream = tqdm(val_loader)\n",
    "    \n",
    "    losses = AverageMeter()\n",
    "    \n",
    "    final_targets = []\n",
    "    final_preds = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # for i, (images, targets) in enumerate(stream, start=1):\n",
    "        for i, (images, targets) in enumerate(val_loader):\n",
    "            images = images.to(CFG.device, non_blocking=True)\n",
    "            targets = targets.to(CFG.device, non_blocking=True)\n",
    "            targets = targets.view(-1, 1)\n",
    "            batch_size = targets.size(0)\n",
    "            \n",
    "            preds = model(images)\n",
    "\n",
    "            loss = criterion(preds, targets)\n",
    "            losses.update(loss.item(), batch_size)\n",
    "\n",
    "            targets_list = (targets.detach().cpu().numpy()).tolist()\n",
    "            preds_list = torch.argmax(preds, dim=1).tolist()\n",
    "            \n",
    "            final_targets.extend(targets_list)\n",
    "            final_preds.extend(preds_list)\n",
    "    return losses.avg, final_preds, final_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_videos ['1606b0e6_0' '1606b0e6_1']\n",
      "valid_videos ['cfbe2e94_0' 'cfbe2e94_1']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1606b0e6_0' '1606b0e6_1' 'cfbe2e94_0' 'cfbe2e94_1']\n"
     ]
    }
   ],
   "source": [
    "train_valid_videos = train_df[\"video_id\"].unique()\n",
    "print(train_valid_videos)\n",
    "train_videos = train_valid_videos[:2]\n",
    "valid_videos = train_valid_videos[2:]\n",
    "if DEBUG:\n",
    "    train_videos = [train_videos[0]]\n",
    "    valid_videos = [valid_videos[0]]\n",
    "LOGGER.info(f\"train_videos {train_videos}\")\n",
    "LOGGER.info(f\"valid_videos {valid_videos}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# separate train/valid data \n",
    "X_train_videoid = train_df[train_df[\"video_id\"].isin(train_videos)][\"video_id\"].values\n",
    "X_train_frame = train_df[train_df[\"video_id\"].isin(train_videos)][\"frame\"].values\n",
    "y_train = train_df[train_df[\"video_id\"].isin(train_videos)][\"event\"].values\n",
    "\n",
    "X_valid_videoid = train_df[train_df[\"video_id\"].isin(valid_videos)][\"video_id\"].values\n",
    "X_valid_frame = train_df[train_df[\"video_id\"].isin(valid_videos)][\"frame\"].values\n",
    "y_valid = train_df[train_df[\"video_id\"].isin(valid_videos)][\"event\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# prepare dataset\n",
    "train_dataset = DFLDataset(video_id= X_train_videoid, frame=X_train_frame, targets = y_train)\n",
    "valid_dataset = DFLDataset(video_id= X_valid_videoid, frame=X_valid_frame, targets = y_valid)\n",
    "\n",
    "# create dataloader\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                        batch_size = CFG.batch_size,\n",
    "                        shuffle = False,\n",
    "                        num_workers = CFG.num_workers)\n",
    "valid_loader = DataLoader(valid_dataset,\n",
    "                        batch_size = CFG.batch_size,\n",
    "                        shuffle = False,\n",
    "                        num_workers = CFG.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# instantiate model, cost function and optimizer\n",
    "model = DFLNet()\n",
    "model = model.to(device)\n",
    "\n",
    "norm_bias_params, non_norm_bias_params = divice_norm_bias(model)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "#print(f\"norm bias params: {len(norm_bias_params)}, non norm bias params: {len(non_norm_bias_params)}\")\n",
    "optimizer = torch.optim.AdamW(\n",
    "    [\n",
    "        {'params': norm_bias_params, 'weight_decay': CFG.opt_wd_norm_bias},\n",
    "        {'params': non_norm_bias_params, 'weight_decay': CFG.opt_wd_non_norm_bias},\n",
    "    ],\n",
    "    eps = CFG.opt_eps,\n",
    "    lr = CFG.lr,\n",
    "    amsgrad = False\n",
    ")\n",
    "\n",
    "# load scaler\n",
    "scheduler = get_scheduler(optimizer)\n",
    "scaler = GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train loss 2.063000,  Valid loss 2.370314. elapsed time:0.2 min.\n",
      "Model is improved.\n",
      "/workdir/work/output/eff_b5_ap_bce_flowimage_1output/tf_efficientnet_b5_ap.pth is saved.\n",
      "Epoch 2: Train loss 1.548859,  Valid loss 2.511300. elapsed time:0.3 min.\n",
      "Epoch 3: Train loss 1.216675,  Valid loss 2.289792. elapsed time:0.5 min.\n",
      "Model is improved.\n",
      "/workdir/work/output/eff_b5_ap_bce_flowimage_1output/tf_efficientnet_b5_ap.pth is saved.\n",
      "Epoch 4: Train loss 0.952859,  Valid loss 2.143212. elapsed time:0.6 min.\n",
      "Model is improved.\n",
      "/workdir/work/output/eff_b5_ap_bce_flowimage_1output/tf_efficientnet_b5_ap.pth is saved.\n",
      "Epoch 5: Train loss 0.734381,  Valid loss 2.086715. elapsed time:0.8 min.\n",
      "Model is improved.\n",
      "/workdir/work/output/eff_b5_ap_bce_flowimage_1output/tf_efficientnet_b5_ap.pth is saved.\n",
      "Epoch 6: Train loss 0.554290,  Valid loss 2.053656. elapsed time:0.9 min.\n",
      "Model is improved.\n",
      "/workdir/work/output/eff_b5_ap_bce_flowimage_1output/tf_efficientnet_b5_ap.pth is saved.\n",
      "Epoch 7: Train loss 0.416705,  Valid loss 2.035138. elapsed time:1.1 min.\n",
      "Model is improved.\n",
      "/workdir/work/output/eff_b5_ap_bce_flowimage_1output/tf_efficientnet_b5_ap.pth is saved.\n",
      "Epoch 8: Train loss 0.318595,  Valid loss 2.024394. elapsed time:1.2 min.\n",
      "Model is improved.\n",
      "/workdir/work/output/eff_b5_ap_bce_flowimage_1output/tf_efficientnet_b5_ap.pth is saved.\n",
      "Epoch 9: Train loss 0.246803,  Valid loss 2.015573. elapsed time:1.4 min.\n",
      "Model is improved.\n",
      "/workdir/work/output/eff_b5_ap_bce_flowimage_1output/tf_efficientnet_b5_ap.pth is saved.\n",
      "Epoch 10: Train loss 0.191940,  Valid loss 2.008186. elapsed time:1.6 min.\n",
      "Model is improved.\n",
      "/workdir/work/output/eff_b5_ap_bce_flowimage_1output/tf_efficientnet_b5_ap.pth is saved.\n",
      "Epoch 11: Train loss 0.149589,  Valid loss 2.002710. elapsed time:1.7 min.\n",
      "Model is improved.\n",
      "/workdir/work/output/eff_b5_ap_bce_flowimage_1output/tf_efficientnet_b5_ap.pth is saved.\n",
      "Epoch 12: Train loss 0.117908,  Valid loss 1.999138. elapsed time:1.9 min.\n",
      "Model is improved.\n",
      "/workdir/work/output/eff_b5_ap_bce_flowimage_1output/tf_efficientnet_b5_ap.pth is saved.\n",
      "Epoch 13: Train loss 0.095186,  Valid loss 1.997265. elapsed time:2.0 min.\n",
      "Model is improved.\n",
      "/workdir/work/output/eff_b5_ap_bce_flowimage_1output/tf_efficientnet_b5_ap.pth is saved.\n",
      "Epoch 14: Train loss 0.078905,  Valid loss 1.995841. elapsed time:2.2 min.\n",
      "Model is improved.\n",
      "/workdir/work/output/eff_b5_ap_bce_flowimage_1output/tf_efficientnet_b5_ap.pth is saved.\n",
      "Epoch 15: Train loss 0.066885,  Valid loss 1.994790. elapsed time:2.3 min.\n",
      "Model is improved.\n",
      "/workdir/work/output/eff_b5_ap_bce_flowimage_1output/tf_efficientnet_b5_ap.pth is saved.\n",
      "Epoch 16: Train loss 0.057825,  Valid loss 1.993914. elapsed time:2.5 min.\n",
      "Model is improved.\n",
      "/workdir/work/output/eff_b5_ap_bce_flowimage_1output/tf_efficientnet_b5_ap.pth is saved.\n",
      "Epoch 17: Train loss 0.051055,  Valid loss 1.993629. elapsed time:2.6 min.\n",
      "Model is improved.\n",
      "/workdir/work/output/eff_b5_ap_bce_flowimage_1output/tf_efficientnet_b5_ap.pth is saved.\n",
      "Epoch 18: Train loss 0.045938,  Valid loss 1.993358. elapsed time:2.8 min.\n",
      "Model is improved.\n",
      "/workdir/work/output/eff_b5_ap_bce_flowimage_1output/tf_efficientnet_b5_ap.pth is saved.\n",
      "Epoch 19: Train loss 0.041845,  Valid loss 1.993223. elapsed time:3.0 min.\n",
      "Model is improved.\n",
      "/workdir/work/output/eff_b5_ap_bce_flowimage_1output/tf_efficientnet_b5_ap.pth is saved.\n",
      "Epoch 20: Train loss 0.038346,  Valid loss 1.992798. elapsed time:3.1 min.\n",
      "Model is improved.\n",
      "/workdir/work/output/eff_b5_ap_bce_flowimage_1output/tf_efficientnet_b5_ap.pth is saved.\n",
      "Epoch 21: Train loss 0.035228,  Valid loss 1.992360. elapsed time:3.3 min.\n",
      "Model is improved.\n",
      "/workdir/work/output/eff_b5_ap_bce_flowimage_1output/tf_efficientnet_b5_ap.pth is saved.\n",
      "Epoch 22: Train loss 0.032570,  Valid loss 1.992131. elapsed time:3.4 min.\n",
      "Model is improved.\n",
      "/workdir/work/output/eff_b5_ap_bce_flowimage_1output/tf_efficientnet_b5_ap.pth is saved.\n",
      "Epoch 23: Train loss 0.030326,  Valid loss 1.991895. elapsed time:3.6 min.\n",
      "Model is improved.\n",
      "/workdir/work/output/eff_b5_ap_bce_flowimage_1output/tf_efficientnet_b5_ap.pth is saved.\n",
      "Epoch 24: Train loss 0.028370,  Valid loss 1.991922. elapsed time:3.7 min.\n",
      "Epoch 25: Train loss 0.026589,  Valid loss 1.991937. elapsed time:3.9 min.\n",
      "Epoch 26: Train loss 0.024938,  Valid loss 1.992008. elapsed time:4.0 min.\n",
      "Epoch 27: Train loss 0.023466,  Valid loss 1.991927. elapsed time:4.2 min.\n",
      "Epoch 28: Train loss 0.022172,  Valid loss 1.991708. elapsed time:4.3 min.\n",
      "Model is improved.\n",
      "/workdir/work/output/eff_b5_ap_bce_flowimage_1output/tf_efficientnet_b5_ap.pth is saved.\n",
      "Epoch 29: Train loss 0.021014,  Valid loss 1.991755. elapsed time:4.5 min.\n",
      "Epoch 30: Train loss 0.019941,  Valid loss 1.991910. elapsed time:4.6 min.\n",
      "Epoch 31: Train loss 0.018914,  Valid loss 1.991922. elapsed time:4.8 min.\n",
      "Epoch 32: Train loss 0.017996,  Valid loss 1.992282. elapsed time:4.9 min.\n",
      "Epoch 33: Train loss 0.017170,  Valid loss 1.992457. elapsed time:5.1 min.\n",
      "Epoch 34: Train loss 0.016412,  Valid loss 1.992346. elapsed time:5.3 min.\n",
      "Epoch 35: Train loss 0.015692,  Valid loss 1.992475. elapsed time:5.4 min.\n",
      "Epoch 36: Train loss 0.015004,  Valid loss 1.992603. elapsed time:5.6 min.\n",
      "Epoch 37: Train loss 0.014368,  Valid loss 1.992474. elapsed time:5.7 min.\n",
      "Epoch 38: Train loss 0.013796,  Valid loss 1.992748. elapsed time:5.9 min.\n",
      "Early stopping. Model is not improved in 10 epochs\n",
      "Learning finished.\n"
     ]
    }
   ],
   "source": [
    "# train / valid loop\n",
    "best_loss = 1e10\n",
    "ealry_stopping_count = 0\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(1, CFG.n_epoch + 1):\n",
    "    train_avg_loss = train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, scaler)\n",
    "    valid_avg_loss, preds, targets = valid_fn(valid_loader, model, criterion, epoch)\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    elapsed_min = elapsed/60\n",
    "    LOGGER.info(f\"Epoch {epoch}: Train loss {train_avg_loss:.6f},  Valid loss {valid_avg_loss:.6f}. elapsed time:{elapsed_min:.1f} min.\")\n",
    "    if valid_avg_loss < best_loss:\n",
    "        LOGGER.info(f\"Model is improved.\")\n",
    "        ealry_stopping_count = 0\n",
    "        best_loss = valid_avg_loss\n",
    "        model_name = CFG.model_path\n",
    "        LOGGER.info(f'{CFG.MODEL_SAVE_DIR}/{model_name}.pth is saved.')\n",
    "        torch.save(model.state_dict(), f'{CFG.MODEL_SAVE_DIR}/{model_name}.pth')\n",
    "\n",
    "    else:\n",
    "        ealry_stopping_count += 1\n",
    "        if ealry_stopping_count >= CFG.early_stopping_rounds:\n",
    "            LOGGER.info(f\"Early stopping. Model is not improved in {CFG.early_stopping_rounds} epochs\")\n",
    "            break\n",
    "del model, train_loader, train_dataset\n",
    "gc.collect()\n",
    "\n",
    "LOGGER.info(\"Learning finished.\")\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
