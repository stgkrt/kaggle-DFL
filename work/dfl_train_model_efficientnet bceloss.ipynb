{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DFL benchmark - training\n",
    "This is a simple benchmark script for DFL.  \n",
    "It classifies each frame image in the video into 4 classes（'background','challenge','play','throwin'） \n",
    "It does not use temporal information, so it may not be competitive on its own for this competition, but it could be used as a feature extractor for more advanced models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Sep 13 12:44:05 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:01:00.0  On |                  N/A |\n",
      "| 44%   50C    P8    38W / 350W |    611MiB / 24576MiB |     43%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import gc\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import timm\n",
    "from timm import utils\n",
    "\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, OneCycleLR, CosineAnnealingLR, ReduceLROnPlateau, StepLR, LambdaLR\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import imageio\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "class CFG:\n",
    "    EXP = \"eff_b5_ap_bce\"\n",
    "\n",
    "    # model\n",
    "    # model_path = \"swint_large224\" #effnetでやってみる？\n",
    "    # model_path =  \"tf_efficientnet_b7_ap\"\n",
    "    model_path =  \"tf_efficientnet_b5_ap\"\n",
    "    MODEL_SAVE_DIR = f\"/workdir/work/output/{EXP}\"\n",
    "    out_features = 4 # output class\n",
    "    inp_channels = 3 #RGB -> 3\n",
    "    dropout = 0\n",
    "    pretrained = True\n",
    "\n",
    "    # train, valid\n",
    "    # TRAIN_CSV = \"/workdir/work/output/saved_train_images.csv\"\n",
    "    TRAIN_IMG_DIR = \"/workdir/work/output/train_images\"\n",
    "    TRAIN_CSV = \"/workdir/work/output/saved_train_event4images.csv\"\n",
    "    TRAIN_IMG_DIR = \"/workdir/work/output/event4image\"\n",
    "    n_fold = 5\n",
    "    random_seed = 42\n",
    "    batch_size = 8\n",
    "    # batch_size = 16\n",
    "    num_workers = 8\n",
    "    n_epoch = 100\n",
    "    early_stopping_rounds = 5\n",
    "    TRAIN_FOLD = [0, 1, 2, 3, 4]\n",
    "\n",
    "    img_height = 224\n",
    "    img_width = 224\n",
    "    if model_path == \"efficientnet_b8\":\n",
    "        img_height = 672\n",
    "        img_width = 672\n",
    "    elif model_path == \"tf_efficientnet_b7_ap\":\n",
    "        img_height = 600\n",
    "        img_width = 600\n",
    "    elif model_path == \"tf_efficientnet_b5_ap\":\n",
    "        img_height = 456\n",
    "        img_width = 456\n",
    "        \n",
    "    #optimizer\n",
    "    gradient_accumulation_steps = 1\n",
    "    max_grad_norm = 1000\n",
    "    opt_eps = 1e-5\n",
    "    # lr = 1e-6\n",
    "    lr = 1e-5\n",
    "    opt_wd_non_norm_bias = 0.01\n",
    "    opt_wd_norm_bias = 0\n",
    "\n",
    "    #scheduler\n",
    "    scheduler_name = \"CosineAnnealingWarmRestarts\"\n",
    "    # scheduler_name = \"OneCycleLR\"\n",
    "    T_0 = 5\n",
    "    # min_lr = 1e-7\n",
    "    # max_lr = 1e-5\n",
    "    min_lr = 1e-7\n",
    "    max_lr = 1e-4\n",
    "    T_max = 5\n",
    "\n",
    "    seed = 42\n",
    "\n",
    "    if DEBUG:\n",
    "        n_epoch = 1\n",
    "        TRAIN_FOLD = [0, 1]\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "CFG.device = device\n",
    "print(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save trained model in this dir\n",
    "if not os.path.exists(CFG.MODEL_SAVE_DIR):\n",
    "    os.makedirs(CFG.MODEL_SAVE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EXP NAME = eff_b5_ap_bce\n",
      "Model = tf_efficientnet_b5_ap, (height, width) = (456, 456)\n"
     ]
    }
   ],
   "source": [
    "def init_logger(log_file=f'{CFG.MODEL_SAVE_DIR}/train_{CFG.EXP}.log'):\n",
    "    \"\"\"Output Log.\"\"\"\n",
    "    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "LOGGER = init_logger()\n",
    "LOGGER.info(f\"EXP NAME = {CFG.EXP}\")\n",
    "LOGGER.info(f\"Model = {CFG.model_path}, (height, width) = ({CFG.img_height}, {CFG.img_width})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_torch(seed=0):\n",
    "    \"\"\"Fixed seed value.\"\"\"\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_torch(seed=CFG.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-14T13:46:56.464484Z",
     "iopub.status.busy": "2022-08-14T13:46:56.46364Z",
     "iopub.status.idle": "2022-08-14T13:46:56.562918Z",
     "shell.execute_reply": "2022-08-14T13:46:56.561751Z",
     "shell.execute_reply.started": "2022-08-14T13:46:56.464445Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>frame</th>\n",
       "      <th>time</th>\n",
       "      <th>event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1606b0e6_0</td>\n",
       "      <td>5005</td>\n",
       "      <td>200.20</td>\n",
       "      <td>background</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1606b0e6_0</td>\n",
       "      <td>5028</td>\n",
       "      <td>201.12</td>\n",
       "      <td>challenge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1606b0e6_0</td>\n",
       "      <td>5070</td>\n",
       "      <td>202.80</td>\n",
       "      <td>background</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1606b0e6_0</td>\n",
       "      <td>5252</td>\n",
       "      <td>210.08</td>\n",
       "      <td>background</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1606b0e6_0</td>\n",
       "      <td>5271</td>\n",
       "      <td>210.84</td>\n",
       "      <td>challenge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11177</th>\n",
       "      <td>ecf251d4_0</td>\n",
       "      <td>76414</td>\n",
       "      <td>3056.56</td>\n",
       "      <td>challenge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11178</th>\n",
       "      <td>ecf251d4_0</td>\n",
       "      <td>76452</td>\n",
       "      <td>3058.08</td>\n",
       "      <td>background</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11179</th>\n",
       "      <td>ecf251d4_0</td>\n",
       "      <td>76706</td>\n",
       "      <td>3068.24</td>\n",
       "      <td>background</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11180</th>\n",
       "      <td>ecf251d4_0</td>\n",
       "      <td>76738</td>\n",
       "      <td>3069.52</td>\n",
       "      <td>throwin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11181</th>\n",
       "      <td>ecf251d4_0</td>\n",
       "      <td>76770</td>\n",
       "      <td>3070.80</td>\n",
       "      <td>background</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11182 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         video_id  frame     time       event\n",
       "0      1606b0e6_0   5005   200.20  background\n",
       "1      1606b0e6_0   5028   201.12   challenge\n",
       "2      1606b0e6_0   5070   202.80  background\n",
       "3      1606b0e6_0   5252   210.08  background\n",
       "4      1606b0e6_0   5271   210.84   challenge\n",
       "...           ...    ...      ...         ...\n",
       "11177  ecf251d4_0  76414  3056.56   challenge\n",
       "11178  ecf251d4_0  76452  3058.08  background\n",
       "11179  ecf251d4_0  76706  3068.24  background\n",
       "11180  ecf251d4_0  76738  3069.52     throwin\n",
       "11181  ecf251d4_0  76770  3070.80  background\n",
       "\n",
       "[11182 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df = pd.read_csv(CFG.TRAIN_CSV)\n",
    "display(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_encoding = {\n",
    "    \"background\" : 0,\n",
    "    \"challenge\" : 1,\n",
    "    \"play\" : 2,\n",
    "    \"throwin\" : 3,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "oe = OneHotEncoder(categories=[[\"background\",\"challenge\",\"play\",\"throwin\"]], sparse=False)\n",
    "\n",
    "class DFLDataset(Dataset):\n",
    "    def __init__(self, video_id, frame, targets, transform=None):\n",
    "        self.video_id = video_id\n",
    "        self.frame = frame\n",
    "        self.targets = targets\n",
    "        # self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = f\"{CFG.TRAIN_IMG_DIR}/{self.video_id[idx]}_{self.frame[idx]:06}.jpg\"\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image, dsize=(CFG.img_height, CFG.img_width))\n",
    "        image = image / 255 # convert to 0-1\n",
    "        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n",
    "        # if self.transform is not None:\n",
    "        #     image = self.transform(image = image)[\"image\"]\n",
    "        target_idx = event_encoding[self.targets[idx]]\n",
    "        target = np.zeros(CFG.out_features).astype(np.float32)\n",
    "        target[target_idx] = 1\n",
    "\n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DFLNet(nn.Module):\n",
    "#     def __init__(self, model_name=CFG.model_path, \n",
    "#                  out_features=CFG.out_features, inp_channels=CFG.inp_channels,\n",
    "#                  pretrained=CFG.pretrained):\n",
    "#         super().__init__()\n",
    "#         self.model = timm.create_model(model_name, pretrained=pretrained, in_chans=inp_channels)\n",
    "#         n_features = self.model.head.in_features\n",
    "#         self.model.head = nn.Linear(n_features, 128)\n",
    "#         self.fc = nn.Sequential(\n",
    "#             nn.Linear(128, 64),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(0.5),\n",
    "#             nn.Linear(64, out_features)\n",
    "#         )\n",
    "#         self.dropout = nn.Dropout(CFG.dropout)\n",
    "    \n",
    "#     def forward(self, image):\n",
    "#         embeddings = self.model(image)\n",
    "#         x = self.dropout(embeddings)\n",
    "#         output = self.fc(x)\n",
    "#         return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DFLNet(nn.Module):\n",
    "    def __init__(self, model_name=CFG.model_path, \n",
    "                 out_features=CFG.out_features, inp_channels=CFG.inp_channels,\n",
    "                 pretrained=CFG.pretrained):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained, in_chans=inp_channels, num_classes=out_features)\n",
    "    \n",
    "    def forward(self, image):\n",
    "        output = self.model(image)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha= 0.25, gamma=2.0, eps=1e-7):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.eps = eps\n",
    "        self.ce = torch.nn.CrossEntropyLoss(reduction=\"none\")\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        logp = self.ce(input, target)\n",
    "        p = torch.exp(-logp)\n",
    "        loss = self.alpha * ((1 - p) ** self.gamma) * logp\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_parameters = [\n",
    "        {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "            'lr': encoder_lr, 'weight_decay': weight_decay},\n",
    "        {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "            'lr': encoder_lr, 'weight_decay': 0.0},\n",
    "        {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n",
    "            'lr': decoder_lr, 'weight_decay': 0.0}\n",
    "    ]\n",
    "    return optimizer_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scheduler(optimizer):\n",
    "    scheduler = None\n",
    "    if CFG.scheduler_name == 'CosineAnnealingWarmRestarts':\n",
    "        scheduler = CosineAnnealingWarmRestarts(\n",
    "            optimizer,\n",
    "            T_0 = CFG.T_0,\n",
    "            eta_min = CFG.min_lr,\n",
    "            last_epoch=-1\n",
    "        )\n",
    "    elif CFG.scheduler_name == 'OneCycleLR':\n",
    "        scheduler = OneCycleLR(\n",
    "            optimizer,\n",
    "            max_lr = CFG.max_lr,\n",
    "            steps_per_epoch = int( ( (CFG.n_fold-1) * train_df.shape[0]) / (CFG.n_fold * CFG.batch_size) ) + 1,\n",
    "            epochs = CFG.n_epoch,\n",
    "        )\n",
    "\n",
    "    elif CFG.scheduler_name == 'CosineAnnealingLR':\n",
    "        scheduler = CosineAnnealingLR(\n",
    "            optimizer,\n",
    "            T_max = CFG.T_max,\n",
    "            eta_min = CFG.min_lr,\n",
    "            last_epoch = -1\n",
    "        )\n",
    "    \n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divice_norm_bias(model): \n",
    "    norm_bias_params = []\n",
    "    non_norm_bias_params = []\n",
    "    except_wd_layers = ['norm', '.bias']\n",
    "    for n, p in model.model.named_parameters():\n",
    "        if any([nd in n for nd in except_wd_layers]):\n",
    "            norm_bias_params.append(p)\n",
    "        else:\n",
    "            non_norm_bias_params.append(p)\n",
    "    return norm_bias_params, non_norm_bias_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "\n",
    "def train_fn(train_loader, model, criterion, optimizer, epoch, scheduler=None, scaler=None):\n",
    "    model.train()\n",
    "    stream = tqdm(train_loader)\n",
    "    losses = AverageMeter()\n",
    "    global_step = 0\n",
    "\n",
    "    for step, (images, targets) in enumerate(stream, start=1):\n",
    "        images = images.to(CFG.device, non_blocking=True)\n",
    "        targets = targets.to(CFG.device, non_blocking=True)\n",
    "        # images = images.to(CFG.device)\n",
    "        # targets = targets.to(CFG.device)\n",
    "        batch_size = targets.size(0) \n",
    "\n",
    "        preds = model(images)\n",
    "        preds_softmax = softmax(preds)\n",
    "\n",
    "        loss = criterion(preds_softmax, targets)\n",
    "        # print(loss)\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "            loss.backward()\n",
    "        else:\n",
    "            loss.backward()\n",
    "        losses.update(loss.item(), batch_size) \n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "            # scheduler.step_update(num_updates=step, metric=losses.avg)\n",
    "\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
    "        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            global_step += 1\n",
    "\n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Valid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_fn(val_loader, model, criterion, epoch):\n",
    "    model.eval()\n",
    "    stream = tqdm(val_loader)\n",
    "    \n",
    "    losses = AverageMeter()\n",
    "    top1_m = AverageMeter()\n",
    "    top5_m = AverageMeter()\n",
    "    \n",
    "    final_targets = []\n",
    "    final_preds = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (images, targets) in enumerate(stream, start=1):\n",
    "            images = images.to(CFG.device, non_blocking=True)\n",
    "            targets = targets.to(CFG.device, non_blocking=True)\n",
    "            # images = images.to(CFG.device)\n",
    "            # targets = targets.to(CFG.device)\n",
    "            preds = model(images)\n",
    "            preds_softmax = softmax(preds)\n",
    "\n",
    "            loss = criterion(preds_softmax, targets)\n",
    "            # acc1, acc5 = utils.accuracy(preds, targets, topk=(1, 5))\n",
    "\n",
    "            losses.update(loss.item(), CFG.batch_size)\n",
    "            # top1_m.update(acc1.item(), CFG.batch_size)\n",
    "            # top5_m.update(acc5.item(), CFG.batch_size)\n",
    "\n",
    "            targets_list = (targets.detach().cpu().numpy()).tolist()\n",
    "            # preds_list = (torch.sigmoid(preds).detach().cpu().numpy()).tolist()\n",
    "            # preds_list = [score_onehot_inv[pred_idx] for pred_idx in torch.argmax(preds, dim=1).tolist()]\n",
    "            preds_list = torch.argmax(preds, dim=1).tolist()\n",
    "            \n",
    "            final_targets.extend(targets_list)\n",
    "            final_preds.extend(preds_list)\n",
    "    return losses.avg, final_preds, final_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_videos ['1606b0e6_0' '1606b0e6_1' '35bd9041_0' '35bd9041_1' '3c993bd2_0'\n",
      " '3c993bd2_1' '407c5a9e_1' '4ffd5986_0' '9a97dae4_1' 'cfbe2e94_0']\n",
      "valid_videos ['cfbe2e94_1' 'ecf251d4_0']\n"
     ]
    }
   ],
   "source": [
    "train_valid_videos = train_df[\"video_id\"].unique()\n",
    "train_videos = train_valid_videos[:10]\n",
    "valid_videos = train_valid_videos[10:]\n",
    "if DEBUG:\n",
    "    train_videos = [train_videos[0]]\n",
    "    valid_videos = [valid_videos[0]]\n",
    "LOGGER.info(f\"train_videos {train_videos}\")\n",
    "LOGGER.info(f\"valid_videos {valid_videos}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate train/valid data \n",
    "X_train_videoid = train_df[train_df[\"video_id\"].isin(train_videos)][\"video_id\"].values\n",
    "X_train_frame = train_df[train_df[\"video_id\"].isin(train_videos)][\"frame\"].values\n",
    "y_train = train_df[train_df[\"video_id\"].isin(train_videos)][\"event\"].values\n",
    "\n",
    "X_valid_videoid = train_df[train_df[\"video_id\"].isin(valid_videos)][\"video_id\"].values\n",
    "X_valid_frame = train_df[train_df[\"video_id\"].isin(valid_videos)][\"frame\"].values\n",
    "y_valid = train_df[train_df[\"video_id\"].isin(valid_videos)][\"event\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare dataset\n",
    "train_dataset = DFLDataset(video_id= X_train_videoid, frame=X_train_frame, targets = y_train)\n",
    "valid_dataset = DFLDataset(video_id= X_valid_videoid, frame=X_valid_frame, targets = y_valid)\n",
    "\n",
    "# create dataloader\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                        batch_size = CFG.batch_size,\n",
    "                        shuffle = False,\n",
    "                        num_workers = CFG.num_workers)\n",
    "valid_loader = DataLoader(valid_dataset,\n",
    "                        batch_size = CFG.batch_size,\n",
    "                        shuffle = False,\n",
    "                        num_workers = CFG.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate model, cost function and optimizer\n",
    "model = DFLNet()\n",
    "model = model.to(device)\n",
    "\n",
    "norm_bias_params, non_norm_bias_params = divice_norm_bias(model)\n",
    "# criterion = FocalLoss()\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "#print(f\"norm bias params: {len(norm_bias_params)}, non norm bias params: {len(non_norm_bias_params)}\")\n",
    "optimizer = torch.optim.AdamW(\n",
    "    [\n",
    "        {'params': norm_bias_params, 'weight_decay': CFG.opt_wd_norm_bias},\n",
    "        {'params': non_norm_bias_params, 'weight_decay': CFG.opt_wd_non_norm_bias},\n",
    "    ],\n",
    "    eps = CFG.opt_eps,\n",
    "    lr = CFG.lr,\n",
    "    amsgrad = False\n",
    ")\n",
    "\n",
    "# load scaler\n",
    "scheduler = get_scheduler(optimizer)\n",
    "scaler = GradScaler()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Sep 13 12:44:11 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:01:00.0  On |                  N/A |\n",
      "| 44%   53C    P2   118W / 350W |   2960MiB / 24576MiB |      7%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b4a1094d9b944d4862aea93309c12ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1181 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "169a12e0922947fa8c03119440a3c225",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train loss 0.497304,  Valid loss 0.496531.\n",
      "Accuracy 0.513218. elapsed time:4.7 min.\n",
      "Model is improved.\n",
      "/workdir/work/output/eff_b5_ap_bce/tf_efficientnet_b5_ap.pth is saved.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfd4c141810f4e56831a99d852c2559a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1181 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c2dc5770bd64c4792aaf8f601cbf77f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train loss 0.301731,  Valid loss 0.502368.\n",
      "Accuracy 0.519540. elapsed time:9.4 min.\n",
      "Model is improved.\n",
      "/workdir/work/output/eff_b5_ap_bce/tf_efficientnet_b5_ap.pth is saved.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01f08721b3a7404cbf7973bcbff61f7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1181 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "463e2646d2794304bdd12db7a65ef32f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train loss 0.186582,  Valid loss 0.524228.\n",
      "Accuracy 0.527586. elapsed time:14.0 min.\n",
      "Model is improved.\n",
      "/workdir/work/output/eff_b5_ap_bce/tf_efficientnet_b5_ap.pth is saved.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26e7a75c99c4496788bf0405f56761bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1181 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52d3ec648817448bb9bbc6f9e25e9d46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train loss 0.098049,  Valid loss 0.560501.\n",
      "Accuracy 0.537931. elapsed time:18.6 min.\n",
      "Model is improved.\n",
      "/workdir/work/output/eff_b5_ap_bce/tf_efficientnet_b5_ap.pth is saved.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b64cc40a9bd845f1be0b25b6d03ab319",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1181 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f650a0190e234ab682078b0abecd7796",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train loss 0.041167,  Valid loss 0.616456.\n",
      "Accuracy 0.543678. elapsed time:23.3 min.\n",
      "Model is improved.\n",
      "/workdir/work/output/eff_b5_ap_bce/tf_efficientnet_b5_ap.pth is saved.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7989038b812d4bd4a7cbb0b59fa9992f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1181 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "189684e9d1ad46048816e44b424d931e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train loss 0.014509,  Valid loss 0.685067.\n",
      "Accuracy 0.550000. elapsed time:27.9 min.\n",
      "Model is improved.\n",
      "/workdir/work/output/eff_b5_ap_bce/tf_efficientnet_b5_ap.pth is saved.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9a8929ebd154ed1bb25b4e8ca05948e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1181 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a06b3ec53ac49afb297519bc4c048cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train loss 0.005365,  Valid loss 0.744695.\n",
      "Accuracy 0.550575. elapsed time:32.5 min.\n",
      "Model is improved.\n",
      "/workdir/work/output/eff_b5_ap_bce/tf_efficientnet_b5_ap.pth is saved.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26a6038438f84fc7aae26dc84a3fcede",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1181 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2acb7f807648464c8fe2ce2e701aae88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train loss 0.003139,  Valid loss 0.857424.\n",
      "Accuracy 0.562069. elapsed time:37.1 min.\n",
      "Model is improved.\n",
      "/workdir/work/output/eff_b5_ap_bce/tf_efficientnet_b5_ap.pth is saved.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cebcb857f0bf404793683853e53a07c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1181 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5739c94ea53a4e71a16d8199eee9b1ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train loss 0.003225,  Valid loss 0.872474.\n",
      "Accuracy 0.556897. elapsed time:41.7 min.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5687b8e137ee40ffaccfaada1ec0f882",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1181 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1b9806eee31406595dde51bf179a86e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train loss 0.010874,  Valid loss 0.862898.\n",
      "Accuracy 0.528736. elapsed time:46.3 min.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96381b38f712483ead380a632844c8d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1181 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c0d87645d074f03b29f090501ac78ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train loss 0.009775,  Valid loss 0.978175.\n",
      "Accuracy 0.567816. elapsed time:50.9 min.\n",
      "Model is improved.\n",
      "/workdir/work/output/eff_b5_ap_bce/tf_efficientnet_b5_ap.pth is saved.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e942602539d1431baefa18d2647a66a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1181 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "531fe94d1cfd4b0cb353f38fa4ea0376",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train loss 0.007066,  Valid loss 0.985110.\n",
      "Accuracy 0.572989. elapsed time:55.5 min.\n",
      "Model is improved.\n",
      "/workdir/work/output/eff_b5_ap_bce/tf_efficientnet_b5_ap.pth is saved.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48c610048b33446fa9ae49314a9e410a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1181 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d55118e9f88c4fa5a367bb40c4239a66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train loss 0.004281,  Valid loss 0.981505.\n",
      "Accuracy 0.571839. elapsed time:60.1 min.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "086b9fc3ad3a46199332e3e5780cde57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1181 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9b7f78eabd14c70a5d37dc4a0b3070e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train loss 0.002202,  Valid loss 0.974361.\n",
      "Accuracy 0.568966. elapsed time:64.7 min.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7c78080e93543f2bd8e6033c86d4ea9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1181 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66946f744f64415ea7cc8e70952321ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: Train loss 0.001845,  Valid loss 0.988439.\n",
      "Accuracy 0.570690. elapsed time:69.3 min.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "998a28358f9e48908f462e3b8bb064c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1181 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "451f681a911942a2963d20f8cc8c74f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: Train loss 0.002058,  Valid loss 0.980661.\n",
      "Accuracy 0.564943. elapsed time:74.0 min.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b7cbf11b1e94dae95cec3b42c42f5c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1181 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f758485af5fb4cee88ba8dea37fcef93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: Train loss 0.001106,  Valid loss 0.982716.\n",
      "Accuracy 0.563218. elapsed time:78.6 min.\n",
      "Early stopping. Model is not improved in 5 epochs\n",
      "Learning finished.\n"
     ]
    }
   ],
   "source": [
    "# train / valid loop\n",
    "best_score = -9999.\n",
    "ealry_stopping_count = 0\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(1, CFG.n_epoch + 1):\n",
    "    train_avg_loss = train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, scaler)\n",
    "    valid_avg_loss, preds, targets = valid_fn(valid_loader, model, criterion, epoch)\n",
    "    accuracy = accuracy_score(np.argmax(targets, axis=1), preds)\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    elapsed_min = elapsed/60\n",
    "    LOGGER.info(f\"Epoch {epoch}: Train loss {train_avg_loss:.6f},  Valid loss {valid_avg_loss:.6f}.\")\n",
    "    # LOGGER.info(f\"Accuracy {accuracy:4f}, Acc@1 {top1_avg_acc:4f}, Acc@5 {top5_avg_acc:4f}. elapsed time:{elapsed_min:.1f} min.\")\n",
    "    LOGGER.info(f\"Accuracy {accuracy:4f}. elapsed time:{elapsed_min:.1f} min.\")\n",
    "    if accuracy > best_score:\n",
    "        # if top1_avg_acc > best_score:\n",
    "        LOGGER.info(f\"Model is improved.\")\n",
    "        ealry_stopping_count = 0\n",
    "        best_score = accuracy\n",
    "        # best_score = top1_avg_acc\n",
    "        model_name = CFG.model_path\n",
    "        LOGGER.info(f'{CFG.MODEL_SAVE_DIR}/{model_name}.pth is saved.')\n",
    "        torch.save(model.state_dict(), f'{CFG.MODEL_SAVE_DIR}/{model_name}.pth')\n",
    "\n",
    "    else:\n",
    "        ealry_stopping_count += 1\n",
    "        if ealry_stopping_count >= CFG.early_stopping_rounds:\n",
    "            LOGGER.info(f\"Early stopping. Model is not improved in {CFG.early_stopping_rounds} epochs\")\n",
    "            break\n",
    "del model, train_loader, train_dataset\n",
    "gc.collect()\n",
    "\n",
    "LOGGER.info(\"Learning finished.\")\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
