{"cells":[{"cell_type":"markdown","metadata":{},"source":["# DFL benchmark - training\n","This is a simple benchmark script for DFL.  \n","It classifies each frame image in the video into 4 classes（'background','challenge','play','throwin'） \n","It does not use temporal information, so it may not be competitive on its own for this competition, but it could be used as a feature extractor for more advanced models."]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Failed to initialize NVML: Unknown Error\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":2,"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.execute_input":"2022-08-14T13:46:55.775793Z","iopub.status.busy":"2022-08-14T13:46:55.775388Z","iopub.status.idle":"2022-08-14T13:46:56.450638Z","shell.execute_reply":"2022-08-14T13:46:56.449685Z","shell.execute_reply.started":"2022-08-14T13:46:55.77575Z"},"trusted":true},"outputs":[],"source":["import os\n","import time\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sn\n","from IPython.display import Video\n","import cv2"]},{"cell_type":"markdown","metadata":{},"source":["# setting"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["DEBUG = False"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["class CFG:\n","    train_csv = \"/workdir/work/input/train.csv\"\n","    result_dir = f\"/workdir/work/output/train_images_flow/\"\n","    arround_time = 1\n","    video_dir = \"/workdir/work/input/train\"\n","\n","    # optical flow settings\n","    # params for ShiTomasi corner detection\n","    feature_params = dict( maxCorners = 100,\n","                        qualityLevel = 0.3,\n","                        minDistance = 7,\n","                        blockSize = 7 )\n","\n","    # Parameters for lucas kanade optical flow\n","    lk_params = dict( winSize  = (15,15),\n","                    maxLevel = 2,\n","                    criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n","    \n","    crop_range = 600\n","    area_thr = 0.1\n","    IMG_SIZE = 456"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["def get_maxflow_area(x, y, width, height, crop_range=CFG.crop_range):\n","    crop_x_min = int(x) - (crop_range/2)\n","    crop_x_max = int(x) + (crop_range/2)\n","    crop_x_min = max(0, crop_x_min)\n","    crop_x_max = min(width, crop_x_max)\n","\n","    crop_y_min = int(y) - (crop_range/2)\n","    crop_y_max = int(y) + (crop_range/2)\n","    crop_y_min = max(0, crop_y_min)\n","    crop_y_max = min(height, crop_y_max)\n","\n","    return int(crop_x_min), int(crop_x_max), int(crop_y_min), int(crop_y_max)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["def get_green_area(img):\n","    # HSV\n","    img_HSV = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n","\n","    # creat green mask (H value for green is from 100/360*179 until 180/360*179) in OpenCV\n","    lower_green = np.array([100 / 360 * 179, 0, 0])\n","    upper_green = np.array([180 / 360 * 179, 255, 255])\n","    green_mask = cv2.inRange(img_HSV, lower_green, upper_green)\n","\n","    # crop green area\n","    img_green_masked = cv2.bitwise_and(img, img, mask=green_mask)\n","    img_green_masked = cv2.cvtColor(img_green_masked, cv2.COLOR_BGR2GRAY)\n","\n","    # Find contours\n","    contours, hierarchy = cv2.findContours(img_green_masked, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n","    if not contours:\n","        return int(img.shape[1]*0.5), int(img.shape[0]*0.5), img.shape[1], img.shape[0]\n","    # Find the contour with the maximum area.\n","    c = max(contours, key=cv2.contourArea)\n","\n","    # Get bounding rectangle\n","    x, y, w, h = cv2.boundingRect(c)\n","\n","    return x, y, w, h"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["def crop_maxflow_area(cap_, fps_, frame_num_, event_):\n","    \"\"\"色相が緑っぽいエリアをフィールドとしてクロップして、optical flowを計算。1secでflowが最も大きい点を中心としてcropする。\n","    \n","    \"\"\"\n","    cap_.set(cv2.CAP_PROP_POS_FRAMES, frame_num_)\n","    successed, base_frame = cap_.read()\n","    if not successed:\n","        return [], 0\n","\n","    # optical flow line color\n","    line_color = [255, 100, 0]\n","    # base frameでフィールドの範囲を決める。1secで大きくカメラ方向が移動するときはだめかも\n","    x_field, y_field, w_field, h_field = get_green_area(base_frame)\n","    base_frame = base_frame[y_field:y_field+h_field, x_field:x_field+w_field, :]\n","\n","    # Take first frame and find corners in it\n","    base_gray = cv2.cvtColor(base_frame, cv2.COLOR_BGR2GRAY)\n","    base_point = cv2.goodFeaturesToTrack(base_gray, mask = None, **CFG.feature_params)\n","    # Create a mask image for drawing purposes\n","    mask = np.zeros_like(base_frame)\n","\n","    # draw the tracks\n","    max_distance = 0\n","    img_max_dist = base_frame\n","\n","    if event_ == \"start\":\n","        frame_num = frame_num_ - fps_\n","        cap_.set(cv2.CAP_PROP_POS_FRAMES, frame_num)\n","    elif event_ == \"end\":\n","        frame_num = frame_num_\n","        cap_.set(cv2.CAP_PROP_POS_FRAMES, frame_num)\n","    else:# play系は0.5秒前から\n","        frame_num = frame_num_ - fps_*0.5\n","        cap_.set(cv2.CAP_PROP_POS_FRAMES, frame_num)\n","\n","    # 1secで基準画像とのoptical flowが最も大きい点を残す\n","    for i in range(int(fps_)):\n","        successed, relative_frame = cap_.read()\n","        if not successed:\n","            continue\n","        frame_num += 1\n","\n","        # base frameで決めたフィールドの範囲をcrop\n","        relative_frame = relative_frame[y_field : y_field+h_field, x_field : x_field+w_field, :]\n","        relative_gray = cv2.cvtColor(relative_frame, cv2.COLOR_BGR2GRAY)\n","\n","        # calculate optical flow\n","        relative_point, st, err = cv2.calcOpticalFlowPyrLK(base_gray, relative_gray, base_point, None, **CFG.lk_params)\n","\n","        # Select good points\n","        good_new = relative_point[st==1]\n","        good_old = base_point[st==1]\n","\n","        x_max_distance = int(x_field + (w_field*0.5))\n","        y_max_distance = int(y_field + (h_field*0.5))\n","        for i, (new, old) in enumerate(zip(good_new, good_old)):\n","            x_after, y_after = new.ravel()\n","            x_before, y_before = old.ravel()\n","            distance = np.sqrt( (x_after - x_before)**2 + (y_after - y_before)**2 )\n","\n","            # distanceが大きい、かつ、検出点が画像の外側area_thr%にないときに移動距離が最大と判定する\n","            if distance > max_distance and (w_field*CFG.area_thr < x_after < w_field*(1.0 -CFG.area_thr)) and (h_field*CFG.area_thr < y_after < y_field*(1.0 - CFG.area_thr)):\n","                max_distance = distance\n","                x_max_distance = x_after\n","                y_max_distance = y_after\n","                # 画像にoptical flow の線を追加する(本当はtop5だけ描くとかの方がいいかも？)\n","                mask = cv2.line(mask, (int(x_after),int(y_after)), (int(x_before), int(y_before)), line_color, 2)\n","                relative_frame = cv2.line(relative_frame, (int(x_after),int(y_after)), (int(x_before), int(y_before)), line_color, 2)\n","                img_max_dist = cv2.circle(relative_frame, (int(x_after),int(y_after)), 5, line_color, -1)\n","\n","    # optical flowの最も大きい点を中心にクロップ(サイズが足りないときは横方向だけとか縦方向だけの場合もあり)\n","    x_min, x_max, y_min, y_max = get_maxflow_area(int(x_max_distance), int(y_max_distance), w_field, h_field)\n","    croped_flow_image = img_max_dist[y_min:y_max, x_min:x_max, :]\n","    croped_flow_image = cv2.resize(croped_flow_image, dsize=(CFG.IMG_SIZE, CFG.IMG_SIZE))\n","\n","    return croped_flow_image, max_distance\n"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# save images around event in result dir\n","if not os.path.exists(CFG.result_dir):\n","    os.makedirs(CFG.result_dir)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-08-14T13:46:56.464484Z","iopub.status.busy":"2022-08-14T13:46:56.46364Z","iopub.status.idle":"2022-08-14T13:46:56.562918Z","shell.execute_reply":"2022-08-14T13:46:56.561751Z","shell.execute_reply.started":"2022-08-14T13:46:56.464445Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>video_id</th>\n","      <th>time</th>\n","      <th>event</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1606b0e6_0</td>\n","      <td>200.265822</td>\n","      <td>start</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1606b0e6_0</td>\n","      <td>201.150000</td>\n","      <td>challenge</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1606b0e6_0</td>\n","      <td>202.765822</td>\n","      <td>end</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1606b0e6_0</td>\n","      <td>210.124111</td>\n","      <td>start</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1606b0e6_0</td>\n","      <td>210.870000</td>\n","      <td>challenge</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>11213</th>\n","      <td>ecf251d4_0</td>\n","      <td>3056.587000</td>\n","      <td>challenge</td>\n","    </tr>\n","    <tr>\n","      <th>11214</th>\n","      <td>ecf251d4_0</td>\n","      <td>3058.072895</td>\n","      <td>end</td>\n","    </tr>\n","    <tr>\n","      <th>11215</th>\n","      <td>ecf251d4_0</td>\n","      <td>3068.280519</td>\n","      <td>start</td>\n","    </tr>\n","    <tr>\n","      <th>11216</th>\n","      <td>ecf251d4_0</td>\n","      <td>3069.547000</td>\n","      <td>throwin</td>\n","    </tr>\n","    <tr>\n","      <th>11217</th>\n","      <td>ecf251d4_0</td>\n","      <td>3070.780519</td>\n","      <td>end</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>11218 rows × 3 columns</p>\n","</div>"],"text/plain":["         video_id         time      event\n","0      1606b0e6_0   200.265822      start\n","1      1606b0e6_0   201.150000  challenge\n","2      1606b0e6_0   202.765822        end\n","3      1606b0e6_0   210.124111      start\n","4      1606b0e6_0   210.870000  challenge\n","...           ...          ...        ...\n","11213  ecf251d4_0  3056.587000  challenge\n","11214  ecf251d4_0  3058.072895        end\n","11215  ecf251d4_0  3068.280519      start\n","11216  ecf251d4_0  3069.547000    throwin\n","11217  ecf251d4_0  3070.780519        end\n","\n","[11218 rows x 3 columns]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["['1606b0e6_0', '1606b0e6_1', 'cfbe2e94_0', 'cfbe2e94_1']\n"]}],"source":["df = pd.read_csv(CFG.train_csv)\n","df = df[[\"video_id\", \"time\", \"event\"]]\n","display(df)\n","# video_ids = df[\"video_id\"].unique()#全動画を対象にする場合はこれ\n","video_ids = [\"1606b0e6_0\", \"1606b0e6_1\", \"cfbe2e94_0\", \"cfbe2e94_1\"]\n","if DEBUG:\n","    video_ids = [\"1606b0e6_0\", \"cfbe2e94_0\"]\n","print(video_ids)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["def make_saved_event_df(save_event_df_, video_id_, frame_, target_, distance_):\n","    save_list = [video_id_, frame_, target_, distance_]\n","    if len(save_event_df_) == 0:\n","        save_event_df_ = pd.DataFrame([save_list], columns=[\"video_id\", \"frame\", \"event\", \"distance\"])\n","    else:\n","        tmp_event_df_ = pd.DataFrame([save_list], columns=[\"video_id\", \"frame\", \"event\", \"distance\"])\n","        save_event_df_ = pd.concat([save_event_df_, tmp_event_df_])\n","    return save_event_df_"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2022-08-14T13:46:56.56544Z","iopub.status.busy":"2022-08-14T13:46:56.565018Z","iopub.status.idle":"2022-08-14T13:51:30.772947Z","shell.execute_reply":"2022-08-14T13:51:30.771633Z","shell.execute_reply.started":"2022-08-14T13:46:56.565397Z"},"trusted":true},"outputs":[],"source":["def extract_training_images(video_id):\n","    saved_image_df = pd.DataFrame()\n","    video_path = f\"{CFG.video_dir}/{video_id}.mp4\"\n","    cap = cv2.VideoCapture(video_path)\n","    fps = cap.get(cv2.CAP_PROP_FPS)\n","    total_frame = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n","    if not cap.isOpened():\n","        print(f\"video {video_path} cannot be opened.\")\n","        return\n","    \n","    df_video = df[df.video_id == video_id]\n","    if DEBUG:\n","        df_video = df_video.head(10)\n","    print(video_id, df_video.shape)\n","\n","    #crr_statu => background, play, challenge, throwin\n","    time_and_event = df_video[['time','event']].values\n","    idx = 0\n","    saved_frame_list = []\n","    save_event_df = pd.DataFrame()\n","    current_frame = 0\n","    start_time = time.time()\n","    elapsed_time_sum = 0\n","    while idx < len(time_and_event):\n","        one_loop_start_time = time.time()\n","        if DEBUG and idx > 3:\n","            break\n","        current_time = time_and_event[idx, 0]\n","        current_event = time_and_event[idx, 1]\n","        current_frame = int(current_time*fps)\n","\n","        if current_event == 'start':\n","            target = 'background'\n","            croped_flow_image, max_distance = crop_maxflow_area(cap, fps, current_frame, current_event)\n","            if max_distance != 0:\n","                out_file = f'{CFG.result_dir}/{video_id}_{current_frame:06}.jpg'\n","                cv2.imwrite(out_file, croped_flow_image)\n","                save_event_df = make_saved_event_df(save_event_df, video_id, current_frame, target, max_distance)\n","            idx += 1\n","        \n","        #endはsaveせずにやってみる\n","        elif current_event == 'end':\n","            idx += 1\n","            continue\n","            # target = 'background'\n","            # croped_flow_image, max_distance = crop_maxflow_area(cap, fps, current_frame, current_event)\n","            # if max_distance != 0:\n","            #     out_file = f'{CFG.result_dir}/{video_id}_{current_frame:06}.jpg'\n","            #     cv2.imwrite(out_file, croped_flow_image)\n","            #     save_event_df = make_saved_event_df(save_event_df, video_id, current_frame, target, max_distance)\n","\n","        else:\n","            target = current_event\n","            croped_flow_image, max_distance = crop_maxflow_area(cap, fps, current_frame, current_event)\n","            if max_distance != 0:\n","                out_file = f'{CFG.result_dir}/{video_id}_{current_frame:06}.jpg'\n","                cv2.imwrite(out_file, croped_flow_image)\n","                save_event_df = make_saved_event_df(save_event_df, video_id, current_frame, target, max_distance)\n","            idx += 1\n","        elapsed_time = time.time() - one_loop_start_time\n","        elapsed_time_sum += elapsed_time\n","        elapsed_time_mean = elapsed_time_sum/idx\n","        print(\"\\r\" + f\"{int(current_frame)} / {int(total_frame)}, elapsed_time={elapsed_time_mean:04f} sec.\", end=\"\")    \n","    \n","    elapsed_time = time.time() - start_time\n","    print(f\"  video {video_id} is finished. elapsed time={(elapsed_time/60):04f} min. saved image num={len(save_event_df)}.\")\n","    save_event_df[\"time\"] = save_event_df[\"frame\"]/fps\n","    return save_event_df"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1606b0e6_0 (1000, 3)\n","75330 / 85915, elapsed_time=0.174660 sec.  video 1606b0e6_0 is finished. elapsed time=2.908842 min. saved image num=359.\n","1606b0e6_1 (1249, 3)\n","84662 / 85138, elapsed_time=0.180230 sec.  video 1606b0e6_1 is finished. elapsed time=3.749716 min. saved image num=385.\n","cfbe2e94_0 (823, 3)\n","80391 / 90500, elapsed_time=0.170834 sec.  video cfbe2e94_0 is finished. elapsed time=2.340875 min. saved image num=560.\n","cfbe2e94_1 (763, 3)\n","89358 / 89925, elapsed_time=0.168430 sec.  video cfbe2e94_1 is finished. elapsed time=2.139463 min. saved image num=518.\n","done\n"]}],"source":["train_images_df = pd.DataFrame()\n","for video_id in video_ids:            \n","    video_event_df = extract_training_images(video_id)\n","    if len(train_images_df) == 0:\n","        train_images_df = video_event_df\n","    else:\n","        train_images_df = pd.concat([train_images_df, video_event_df])\n","print('done')"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Completed.\n"]}],"source":["train_images_df.to_csv(\"/workdir/work/output/saved_train_flowimages.csv\", index=False)\n","print(\"Completed.\")"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"text/plain":["1822"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["len(train_images_df)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"text/plain":["<bound method IndexOpsMixin.value_counts of 0    background\n","0    background\n","0          play\n","0    background\n","0          play\n","        ...    \n","0          play\n","0    background\n","0          play\n","0    background\n","0       throwin\n","Name: event, Length: 1822, dtype: object>"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["train_images_df[\"event\"].value_counts"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"text/plain":["play          831\n","background    808\n","challenge     125\n","throwin        58\n","Name: event, dtype: int64"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["train_images_df[\"event\"].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
