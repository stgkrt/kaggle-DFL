{"cells":[{"cell_type":"markdown","metadata":{},"source":["# DFL benchmark - training\n","This is a simple benchmark script for DFL.  \n","It classifies each frame image in the video into 4 classes（'background','challenge','play','throwin'） \n","It does not use temporal information, so it may not be competitive on its own for this competition, but it could be used as a feature extractor for more advanced models."]},{"cell_type":"code","execution_count":42,"metadata":{"vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Failed to initialize NVML: Unknown Error\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":43,"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.execute_input":"2022-08-14T13:46:55.775793Z","iopub.status.busy":"2022-08-14T13:46:55.775388Z","iopub.status.idle":"2022-08-14T13:46:56.450638Z","shell.execute_reply":"2022-08-14T13:46:56.449685Z","shell.execute_reply.started":"2022-08-14T13:46:55.77575Z"},"trusted":true,"vscode":{"languageId":"python"}},"outputs":[],"source":["import os\n","import time\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sn\n","from IPython.display import Video\n","import cv2"]},{"cell_type":"markdown","metadata":{},"source":["# setting"]},{"cell_type":"code","execution_count":44,"metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":["DEBUG = True"]},{"cell_type":"code","execution_count":45,"metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":["class CFG:\n","    train_csv = \"/workdir/work/input/train.csv\"\n","    video_dir = \"/workdir/work/input/train\"\n","\n","    result_dir = f\"/workdir/work/output/train_images_flowvec/\"\n","    output_train_csv = \"/workdir/work/output/train_images_flowvec.csv\"\n","\n","    # optical flow settings\n","    # params for ShiTomasi corner detection\n","    feature_params = dict( maxCorners = 100,\n","                        qualityLevel = 0.3,\n","                        minDistance = 7,\n","                        blockSize = 7 )\n","\n","    # Parameters for lucas kanade optical flow\n","    lk_params = dict( winSize  = (15,15),\n","                    maxLevel = 2,\n","                    criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n","    \n","    CAL_FLOW_TIME = 0.3\n","    skip_time_interval = 0.3\n","    crop_range = 800\n","    area_thr = 0.2\n","    IMG_SIZE = 456\n","    dis_thr = 5.0"]},{"cell_type":"markdown","metadata":{},"source":["# Scoring functions"]},{"cell_type":"code","execution_count":46,"metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":["# copy from https://www.kaggle.com/code/ryanholbrook/competition-metric-dfl-event-detection-ap\n","\n","import numpy as np\n","import pandas as pd\n","from pandas.testing import assert_index_equal\n","from typing import Dict, Tuple\n","\n","tolerances = {\n","    \"challenge\": [0.3, 0.4, 0.5, 0.6, 0.7],\n","    \"play\": [0.15, 0.20, 0.25, 0.30, 0.35],\n","    \"throwin\": [0.15, 0.20, 0.25, 0.30, 0.35],\n","}\n","\n","def filter_detections(\n","        detections: pd.DataFrame, intervals: pd.DataFrame\n",") -> pd.DataFrame:\n","    \"\"\"Drop detections not inside a scoring interval.\"\"\"\n","    detection_time = detections.loc[:, 'time'].sort_values().to_numpy()\n","    intervals = intervals.to_numpy()\n","    is_scored = np.full_like(detection_time, False, dtype=bool)\n","\n","    i, j = 0, 0\n","    while i < len(detection_time) and j < len(intervals):\n","        time = detection_time[i]\n","        int_ = intervals[j]\n","\n","        # If the detection is prior in time to the interval, go to the next detection.\n","        if time < int_.left:\n","            i += 1\n","        # If the detection is inside the interval, keep it and go to the next detection.        \n","        elif time in int_:\n","            is_scored[i] = True\n","            i += 1\n","        # If the detection is later in time, go to the next interval.\n","        else:\n","            j += 1\n","\n","    return detections.loc[is_scored].reset_index(drop=True)\n","\n","\n","def match_detections(\n","        tolerance: float, ground_truths: pd.DataFrame, detections: pd.DataFrame\n",") -> pd.DataFrame:\n","    \"\"\"Match detections to ground truth events. Arguments are taken from a common event x tolerance x video evaluation group.\"\"\"\n","    detections_sorted = detections.sort_values('score', ascending=False).dropna()\n","\n","    is_matched = np.full_like(detections_sorted['event'], False, dtype=bool)\n","    gts_matched = set()\n","    for i, det in enumerate(detections_sorted.itertuples(index=False)):\n","        best_error = tolerance\n","        best_gt = None\n","\n","        for gt in ground_truths.itertuples(index=False):\n","            error = abs(det.time - gt.time)\n","            if error < best_error and not gt in gts_matched:\n","                best_gt = gt\n","                best_error = error\n","            \n","        if best_gt is not None:\n","            is_matched[i] = True\n","            gts_matched.add(best_gt)\n","\n","    detections_sorted['matched'] = is_matched\n","\n","    return detections_sorted\n","\n","\n","def precision_recall_curve(\n","        matches: np.ndarray, scores: np.ndarray, p: int\n",") -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n","    if len(matches) == 0:\n","        return [1], [0], []\n","\n","    # Sort matches by decreasing confidence\n","    idxs = np.argsort(scores, kind='stable')[::-1]\n","    scores = scores[idxs]\n","    matches = matches[idxs]\n","    \n","    distinct_value_indices = np.where(np.diff(scores))[0]\n","    threshold_idxs = np.r_[distinct_value_indices, matches.size - 1]\n","    thresholds = scores[threshold_idxs]\n","    \n","    # Matches become TPs and non-matches FPs as confidence threshold decreases\n","    tps = np.cumsum(matches)[threshold_idxs]\n","    fps = np.cumsum(~matches)[threshold_idxs]\n","    \n","    precision = tps / (tps + fps)\n","    precision[np.isnan(precision)] = 0\n","    recall = tps / p  # total number of ground truths might be different than total number of matches\n","    \n","    # Stop when full recall attained and reverse the outputs so recall is non-increasing.\n","    last_ind = tps.searchsorted(tps[-1])\n","    sl = slice(last_ind, None, -1)\n","\n","    # Final precision is 1 and final recall is 0\n","    return np.r_[precision[sl], 1], np.r_[recall[sl], 0], thresholds[sl]\n","\n","\n","def average_precision_score(matches: np.ndarray, scores: np.ndarray, p: int) -> float:\n","    precision, recall, _ = precision_recall_curve(matches, scores, p)\n","    # Compute step integral\n","    return -np.sum(np.diff(recall) * np.array(precision)[:-1])\n","\n","\n","def event_detection_ap(\n","        solution: pd.DataFrame,\n","        submission: pd.DataFrame,\n","        tolerances: Dict[str, float],\n",") -> float:\n","\n","    assert_index_equal(solution.columns, pd.Index(['video_id', 'time', 'event']))\n","    assert_index_equal(submission.columns, pd.Index(['video_id', 'time', 'event', 'score']))\n","\n","    # Ensure solution and submission are sorted properly\n","    solution = solution.sort_values(['video_id', 'time'])\n","    submission = submission.sort_values(['video_id', 'time'])\n","    \n","    # Extract scoring intervals.\n","    intervals = (\n","        solution\n","        .query(\"event in ['start', 'end']\")\n","        .assign(interval=lambda x: x.groupby(['video_id', 'event']).cumcount())\n","        .pivot(index='interval', columns=['video_id', 'event'], values='time')\n","        .stack('video_id')\n","        .swaplevel()\n","        .sort_index()\n","        .loc[:, ['start', 'end']]\n","        .apply(lambda x: pd.Interval(*x, closed='both'), axis=1)\n","    )\n","\n","    # Extract ground-truth events.\n","    ground_truths = (\n","        solution\n","        .query(\"event not in ['start', 'end']\")\n","        .reset_index(drop=True)\n","    )\n","\n","    # Map each event class to its prevalence (needed for recall calculation)\n","    class_counts = ground_truths.value_counts('event').to_dict()\n","\n","    # Create table for detections with a column indicating a match to a ground-truth event\n","    detections = submission.assign(matched = False)\n","\n","    # Remove detections outside of scoring intervals\n","    detections_filtered = []\n","    for (det_group, dets), (int_group, ints) in zip(\n","        detections.groupby('video_id'), intervals.groupby('video_id')\n","    ):\n","        assert det_group == int_group\n","        detections_filtered.append(filter_detections(dets, ints))\n","    detections_filtered = pd.concat(detections_filtered, ignore_index=True)\n","\n","    # Create table of event-class x tolerance x video_id values\n","    aggregation_keys = pd.DataFrame(\n","        [(ev, tol, vid)\n","         for ev in tolerances.keys()\n","         for tol in tolerances[ev]\n","         for vid in ground_truths['video_id'].unique()],\n","        columns=['event', 'tolerance', 'video_id'],\n","    )\n","\n","    # Create match evaluation groups: event-class x tolerance x video_id\n","    detections_grouped = (\n","        aggregation_keys\n","        .merge(detections_filtered, on=['event', 'video_id'], how='left')\n","        .groupby(['event', 'tolerance', 'video_id'])\n","    )\n","    ground_truths_grouped = (\n","        aggregation_keys\n","        .merge(ground_truths, on=['event', 'video_id'], how='left')\n","        .groupby(['event', 'tolerance', 'video_id'])\n","    )\n","    \n","    # Match detections to ground truth events by evaluation group\n","    detections_matched = []\n","    for key in aggregation_keys.itertuples(index=False):\n","        dets = detections_grouped.get_group(key)\n","        gts = ground_truths_grouped.get_group(key)\n","        detections_matched.append(\n","            match_detections(dets['tolerance'].iloc[0], gts, dets)\n","        )\n","    detections_matched = pd.concat(detections_matched)\n","    \n","    # Compute AP per event x tolerance group\n","    event_classes = ground_truths['event'].unique()\n","    ap_table = (\n","        detections_matched\n","        .query(\"event in @event_classes\")\n","        .groupby(['event', 'tolerance']).apply(\n","        lambda group: average_precision_score(\n","        group['matched'].to_numpy(),\n","                group['score'].to_numpy(),\n","                class_counts[group['event'].iat[0]],\n","            )\n","        )\n","    )\n","\n","    # Average over tolerances, then over event classes\n","    mean_ap = ap_table.groupby('event').mean().mean()\n","\n","    return mean_ap"]},{"cell_type":"markdown","metadata":{},"source":["# optical flow functions"]},{"cell_type":"code","execution_count":47,"metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":["def get_maxflow_area(x, y, width, height, crop_range=CFG.crop_range):\n","    crop_x_min = int(x) - (crop_range/2)\n","    crop_x_max = int(x) + (crop_range/2)\n","    crop_x_min = max(0, crop_x_min)\n","    crop_x_max = min(width, crop_x_max)\n","\n","    crop_y_min = int(y) - (crop_range/2)\n","    crop_y_max = int(y) + (crop_range/2)\n","    crop_y_min = max(0, crop_y_min)\n","    crop_y_max = min(height, crop_y_max)\n","\n","    return int(crop_x_min), int(crop_x_max), int(crop_y_min), int(crop_y_max)"]},{"cell_type":"code","execution_count":48,"metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":["def get_green_area(img):\n","    # HSV\n","    img_HSV = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n","\n","    # creat green mask (H value for green is from 100/360*179 until 180/360*179) in OpenCV\n","    lower_green = np.array([100 / 360 * 179, 0, 0])\n","    upper_green = np.array([180 / 360 * 179, 255, 255])\n","    green_mask = cv2.inRange(img_HSV, lower_green, upper_green)\n","\n","    # crop green area\n","    img_green_masked = cv2.bitwise_and(img, img, mask=green_mask)\n","    img_green_masked = cv2.cvtColor(img_green_masked, cv2.COLOR_BGR2GRAY)\n","\n","    # Find contours\n","    contours, hierarchy = cv2.findContours(img_green_masked, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n","    if not contours:\n","        return int(img.shape[1]*0.5), int(img.shape[0]*0.5), img.shape[1], img.shape[0]\n","    # Find the contour with the maximum area.\n","    c = max(contours, key=cv2.contourArea)\n","\n","    # Get bounding rectangle\n","    x, y, w, h = cv2.boundingRect(c)\n","\n","    return x, y, w, h"]},{"cell_type":"code","execution_count":49,"metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":["from numpy import linalg as LA\n","\n","def get_angle(u, v):\n","    i = np.inner(u, v)\n","    n = LA.norm(u) * LA.norm(v)\n","    if n == 0:\n","        return 90\n","    else:\n","        c = i / n\n","        return np.rad2deg(np.arccos(np.clip(c, -1.0, 1.0)))"]},{"cell_type":"code","execution_count":50,"metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":["def is_point_inarea(points_, width_, height_, area_thr_=CFG.area_thr):\n","    is_inarea = []\n","    width_min = width_*area_thr_\n","    width_max = width_*(1-area_thr_)\n","    height_min = height_*area_thr_\n","    height_max = height_*(1-area_thr_)\n","    for point in points_:\n","        if (width_min <= point[0][0] <= width_max) and (height_min <= point[0][1] <= height_max):\n","            is_inarea.append([True])\n","        else:\n","            is_inarea.append([False])\n","    \n","    return is_inarea"]},{"cell_type":"code","execution_count":51,"metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":["def get_2optflows(cap_, fps_, frame_num_):\n","    cap_.set(cv2.CAP_PROP_POS_FRAMES, frame_num_)\n","    successed, base_frame = cap_.read()\n","    if not successed:\n","        return [], -1, -1\n","\n","    # optical flow line color\n","    line_color = [255, 100, 0]\n","    # base frameでフィールドの範囲を決める。1secで大きくカメラ方向が移動するときはだめかも\n","    x_field, y_field, w_field, h_field = get_green_area(base_frame)\n","    base_frame = base_frame[y_field:y_field+h_field, x_field:x_field+w_field, :]\n","\n","    # Take first frame and find corners in it\n","    base_gray = cv2.cvtColor(base_frame, cv2.COLOR_BGR2GRAY)\n","    base_point = cv2.goodFeaturesToTrack(base_gray, mask = None, **CFG.feature_params)\n","    # Create a mask image for drawing purposes\n","    mask = np.zeros_like(base_frame)\n","\n","    # draw the tracks\n","    max_distance = 0\n","    img_max_dist = base_frame\n","\n","    # 指定時間後の画像と比較してoptical flowベクトルを計算する\n","    cap_.set(cv2.CAP_PROP_POS_FRAMES, frame_num_)\n","    successed, relative_frame = cap_.read()\n","    if not successed:\n","        return [], -1, -1\n","\n","    # base frameで決めたフィールドの範囲をcrop\n","    relative_frame = relative_frame[y_field : y_field+h_field, x_field : x_field+w_field, :]\n","    relative_gray = cv2.cvtColor(relative_frame, cv2.COLOR_BGR2GRAY)\n","\n","    # calculate optical flow\n","    relative_point, st, err = cv2.calcOpticalFlowPyrLK(base_gray, relative_gray, base_point, None, **CFG.lk_params)\n","\n","    # Select good points\n","    good_new = relative_point[st==1]\n","    good_old = base_point[st==1]\n"]},{"cell_type":"code","execution_count":52,"metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":["def crop_flowvec_area(cap_, fps_, frame_num_):\n","    \"\"\"色相が緑っぽいエリアをフィールドとしてクロップして、optical flowを計算。1secでflowが最も大きい点を中心としてcropする。\n","    \n","    \"\"\"\n","    cap_.set(cv2.CAP_PROP_POS_FRAMES, frame_num_)\n","    successed, base_frame = cap_.read()\n","    if not successed:\n","        return [], -300, -300\n","\n","    # optical flow line color\n","    line_color = [255, 100, 0]\n","    # base frameでフィールドの範囲を決める。1secで大きくカメラ方向が移動するときはだめかも\n","    x_field, y_field, w_field, h_field = get_green_area(base_frame)\n","    base_frame = base_frame[y_field:y_field+h_field, x_field:x_field+w_field, :]\n","\n","    # Take first frame and find corners in it\n","    base_gray = cv2.cvtColor(base_frame, cv2.COLOR_BGR2GRAY)\n","    base_point = cv2.goodFeaturesToTrack(base_gray, mask = None, **CFG.feature_params)\n","    # Create a mask image for drawing purposes\n","    mask = np.zeros_like(base_frame)\n","\n","    # draw the tracks\n","    max_distance = 0\n","    img_max_dist = base_frame\n","\n","    # 指定時間後の画像と比較してoptical flowベクトルを計算する\n","    frame_num_ += int(fps_*CFG.CAL_FLOW_TIME)\n","    cap_.set(cv2.CAP_PROP_POS_FRAMES, frame_num_)\n","    successed, relative_frame1 = cap_.read()\n","    if not successed:\n","        return [], -300, -300\n","\n","    # base frameで決めたフィールドの範囲をcrop\n","    relative_frame1 = relative_frame1[y_field : y_field+h_field, x_field : x_field+w_field, :]\n","    relative_gray1 = cv2.cvtColor(relative_frame1, cv2.COLOR_BGR2GRAY)\n","    relative_point_1, deteceted_status_1, _ = cv2.calcOpticalFlowPyrLK(base_gray, relative_gray1, base_point, True, **CFG.lk_params)\n","\n","\n","    # さらに指定時間後の画像と比較してoptical flowベクトルを計算する\n","    frame_num_ += int(fps_*CFG.CAL_FLOW_TIME)\n","    cap_.set(cv2.CAP_PROP_POS_FRAMES, frame_num_)\n","    successed, relative_frame2 = cap_.read()\n","    if not successed:\n","        return [], -300, -300\n","\n","    # base frameで決めたフィールドの範囲をcrop\n","    relative_frame2 = relative_frame2[y_field : y_field+h_field, x_field : x_field+w_field, :]\n","    relative_gray2 = cv2.cvtColor(relative_frame2, cv2.COLOR_BGR2GRAY)\n","    relative_point_2, deteceted_status_2, _ = cv2.calcOpticalFlowPyrLK(relative_gray1, relative_gray2, base_point, True, **CFG.lk_params)\n","\n","    # 2回のflow計算でともに対応点が見つかったものを使う\n","    is_inarea_base = is_point_inarea(base_point, base_frame.shape[1], base_frame.shape[0])\n","    is_inarea_relative1 = is_point_inarea(relative_point_1, base_frame.shape[1], base_frame.shape[0])\n","    is_inarea_relative2 = is_point_inarea(relative_point_1, base_frame.shape[1], base_frame.shape[0])\n","\n","    detected_status = deteceted_status_1 * deteceted_status_2\n","    detected_status = detected_status * is_inarea_relative1* is_inarea_relative2\n","    base_point = base_point[detected_status == 1]\n","    relative_point_1 = relative_point_1[detected_status == 1]\n","    relative_point_2 = relative_point_2[detected_status == 1]\n","\n","    if len(base_point) == 0:\n","        return [], 0, 0\n","\n","    vec1 = relative_point_1 - base_point\n","    # vec2 = relative_point_2 - base_point\n","    vec2 = relative_point_2 - relative_point_1\n","\n","    points_angle = []\n","    for v1, v2 in zip(vec1, vec2):\n","        points_angle.append(get_angle(v1, v2))\n","    mean_angle = np.mean(points_angle)\n","    max_angle = np.max(points_angle)\n","\n","    detected_points = np.concatenate([base_point, relative_point_1, relative_point_2])\n","    x_max, y_max = np.max(detected_points, axis=0)\n","    x_min, y_min = np.min(detected_points, axis=0)\n","\n","    # croped_flow_image = img_max_dist[int(y_min):int(y_max), int(x_min):int(x_max), :]\n","    # croped_flow_image = cv2.resize(croped_flow_image, dsize=(CFG.IMG_SIZE, CFG.IMG_SIZE))\n","\n","    return [], mean_angle, max_angle\n"]},{"cell_type":"markdown","metadata":{},"source":["# Load data"]},{"cell_type":"code","execution_count":53,"metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":["# save images around event in result dir\n","if not os.path.exists(CFG.result_dir):\n","    os.makedirs(CFG.result_dir)"]},{"cell_type":"code","execution_count":54,"metadata":{"execution":{"iopub.execute_input":"2022-08-14T13:46:56.464484Z","iopub.status.busy":"2022-08-14T13:46:56.46364Z","iopub.status.idle":"2022-08-14T13:46:56.562918Z","shell.execute_reply":"2022-08-14T13:46:56.561751Z","shell.execute_reply.started":"2022-08-14T13:46:56.464445Z"},"trusted":true,"vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["['1606b0e6_0']\n"]}],"source":["df = pd.read_csv(CFG.train_csv)\n","df = df[[\"video_id\", \"time\", \"event\"]]\n","# video_ids = df[\"video_id\"].unique()#全動画を対象にする場合はこれ\n","video_ids = [\"1606b0e6_0\", \"1606b0e6_1\"]\n","if DEBUG:\n","    video_ids = [\"1606b0e6_0\"]\n","print(video_ids)"]},{"cell_type":"markdown","metadata":{},"source":["# Extract training images fucntion"]},{"cell_type":"code","execution_count":55,"metadata":{"execution":{"iopub.execute_input":"2022-08-14T13:46:56.56544Z","iopub.status.busy":"2022-08-14T13:46:56.565018Z","iopub.status.idle":"2022-08-14T13:51:30.772947Z","shell.execute_reply":"2022-08-14T13:51:30.771633Z","shell.execute_reply.started":"2022-08-14T13:46:56.565397Z"},"trusted":true,"vscode":{"languageId":"python"}},"outputs":[],"source":["def extract_training_images(video_id):\n","    saved_image_df = pd.DataFrame()\n","    video_path = f\"{CFG.video_dir}/{video_id}.mp4\"\n","    cap = cv2.VideoCapture(video_path)\n","    if not cap.isOpened():\n","        print(f\"video {video_path} cannot be opened.\")\n","        return\n","    \n","    fps = cap.get(cv2.CAP_PROP_FPS)\n","    total_frame = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n","\n","    valid_list = []\n","    frame_num = 1\n","    while True:\n","        frame_image, angle_mean, max_angle = crop_flowvec_area(cap, fps, frame_num)\n","        if angle_mean == -300:\n","            break\n","        current_time = frame_num/fps\n","        valid_list.append([video_id, current_time, \"play\", 1.0, angle_mean, max_angle])\n","        valid_list.append([video_id, current_time, \"challenge\", 1.0, angle_mean, max_angle])\n","        valid_list.append([video_id, current_time, \"throwin\", 1.0, angle_mean, max_angle])\n","        frame_num += int(fps*CFG.CAL_FLOW_TIME)        \n","    \n","    valid_df = pd.DataFrame(valid_list, columns=[\"video_id\", \"time\", \"event\", \"score\", \"angle\", \"max_angle\"])\n","    return valid_df"]},{"cell_type":"code","execution_count":56,"metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":["def extract_base_valid(video_id):\n","    saved_image_df = pd.DataFrame()\n","    video_path = f\"{CFG.video_dir}/{video_id}.mp4\"\n","    cap = cv2.VideoCapture(video_path)\n","    if not cap.isOpened():\n","        print(f\"video {video_path} cannot be opened.\")\n","        return\n","    \n","    fps = cap.get(cv2.CAP_PROP_FPS)\n","    total_frame = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n","\n","    valid_list = []\n","    frame_num = 1\n","    for frame in range(int(total_frame)):\n","        current_time = frame/fps\n","        valid_list.append([video_id, current_time, \"play\", 1.0])\n","        valid_list.append([video_id, current_time, \"challenge\", 1.0])\n","        valid_list.append([video_id, current_time, \"throwin\", 1.0])      \n","    \n","    valid_df = pd.DataFrame(valid_list, columns=[\"video_id\", \"time\", \"event\", \"score\"])\n","    return valid_df"]},{"cell_type":"code","execution_count":57,"metadata":{"vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["\t video 1606b0e6_0 is finished.\n","done\n"]}],"source":["validation_df = pd.DataFrame()\n","for video_id in video_ids:            \n","    video_event_df = extract_training_images(video_id)\n","    print(f\"\\t video {video_id} is finished.\")\n","    if len(validation_df) == 0:\n","        validation_df = video_event_df\n","    else:\n","        validation_df = pd.concat([validation_df, video_event_df])\n","\n","print('done')"]},{"cell_type":"code","execution_count":58,"metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":["# base_df = pd.DataFrame()\n","# for video_id in video_ids:            \n","#     video_event_df = extract_base_valid(video_id)\n","#     print(f\"\\t video {video_id} is finished.\")\n","#     if len(base_df) == 0:\n","#         base_df = video_event_df\n","#     else:\n","#         base_df = pd.concat([base_df, video_event_df])\n","\n","# print('done')"]},{"cell_type":"code","execution_count":59,"metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":["validation_df.to_csv(\"/workdir/work/output/include_angle_train.csv\", index=False)\n","# base_df.to_csv(\"/workdir/work/output/base_valid.csv\", index=False)"]},{"cell_type":"code","execution_count":60,"metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":["valid_score_df = validation_df[[\"video_id\", \"time\", \"event\", \"score\"]]"]},{"cell_type":"markdown","metadata":{},"source":["# validation scoring"]},{"cell_type":"code","execution_count":61,"metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":["solution = pd.read_csv(\"/workdir/work/input/train.csv\", usecols=['video_id', 'time', 'event'])"]},{"cell_type":"code","execution_count":62,"metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":["# score_base = event_detection_ap(solution[solution['video_id'].isin(video_ids)], base_df, tolerances)\n","# print(score_base)"]},{"cell_type":"markdown","metadata":{},"source":["0.005654800154221822"]},{"cell_type":"code","execution_count":63,"metadata":{"vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["0.039603960396039604\n","0.09570957095709572\n","0.0063006300630063005\n","0.0168016801680168\n"]}],"source":["valid_score_df = validation_df[[\"video_id\", \"time\", \"event\", \"score\"]]\n","score = event_detection_ap(solution[solution['video_id'].isin(video_ids)], valid_score_df, tolerances)\n","print(score)\n","\n","valid_score_df = validation_df[validation_df[\"event\"] == \"play\"]\n","valid_score_df = valid_score_df[[\"video_id\", \"time\", \"event\", \"score\"]]\n","score = event_detection_ap(solution[solution['video_id'].isin(video_ids)], valid_score_df, tolerances)\n","print(score)\n","\n","valid_score_df = validation_df[validation_df[\"event\"] == \"throwin\"]\n","valid_score_df = valid_score_df[[\"video_id\", \"time\", \"event\", \"score\"]]\n","score = event_detection_ap(solution[solution['video_id'].isin(video_ids)], valid_score_df, tolerances)\n","print(score)\n","\n","\n","valid_score_df = validation_df[validation_df[\"event\"] == \"challenge\"]\n","valid_score_df = valid_score_df[[\"video_id\", \"time\", \"event\", \"score\"]]\n","score = event_detection_ap(solution[solution['video_id'].isin(video_ids)], valid_score_df, tolerances)\n","print(score)"]},{"cell_type":"code","execution_count":64,"metadata":{"vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["0.03926951854178612\n","0.09252544945002603\n","0.00646811374726569\n","0.018814992428066633\n"]}],"source":["thr = 70\n","valid_score_df = validation_df[validation_df[\"angle\"] > thr]\n","valid_score_df = valid_score_df[[\"video_id\", \"time\", \"event\", \"score\"]]\n","score = event_detection_ap(solution[solution['video_id'].isin(video_ids)], valid_score_df, tolerances)\n","print(score)\n","\n","valid_score_df = validation_df[validation_df[\"angle\"] > thr]\n","valid_score_df = valid_score_df[valid_score_df[\"event\"] == \"play\"]\n","valid_score_df = valid_score_df[[\"video_id\", \"time\", \"event\", \"score\"]]\n","score = event_detection_ap(solution[solution['video_id'].isin(video_ids)], valid_score_df, tolerances)\n","print(score)\n","\n","valid_score_df = validation_df[validation_df[\"angle\"] > thr]\n","valid_score_df = valid_score_df[valid_score_df[\"event\"] == \"throwin\"]\n","valid_score_df = valid_score_df[[\"video_id\", \"time\", \"event\", \"score\"]]\n","score = event_detection_ap(solution[solution['video_id'].isin(video_ids)], valid_score_df, tolerances)\n","print(score)\n","\n","valid_score_df = validation_df[validation_df[\"angle\"] > thr]\n","valid_score_df = valid_score_df[valid_score_df[\"event\"] == \"challenge\"]\n","valid_score_df = valid_score_df[[\"video_id\", \"time\", \"event\", \"score\"]]\n","score = event_detection_ap(solution[solution['video_id'].isin(video_ids)], valid_score_df, tolerances)\n","print(score)"]},{"cell_type":"code","execution_count":65,"metadata":{"vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["0.04077484962325561\n","0.09422769813140666\n","0.004695095261132997\n","0.023401755477227178\n"]}],"source":["thr = 100\n","valid_score_df = validation_df[validation_df[\"angle\"] > thr]\n","valid_score_df = valid_score_df[[\"video_id\", \"time\", \"event\", \"score\"]]\n","score = event_detection_ap(solution[solution['video_id'].isin(video_ids)], valid_score_df, tolerances)\n","print(score)\n","\n","valid_score_df = validation_df[validation_df[\"angle\"] > thr]\n","valid_score_df = valid_score_df[valid_score_df[\"event\"] == \"play\"]\n","valid_score_df = valid_score_df[[\"video_id\", \"time\", \"event\", \"score\"]]\n","score = event_detection_ap(solution[solution['video_id'].isin(video_ids)], valid_score_df, tolerances)\n","print(score)\n","\n","valid_score_df = validation_df[validation_df[\"angle\"] > thr]\n","valid_score_df = valid_score_df[valid_score_df[\"event\"] == \"throwin\"]\n","valid_score_df = valid_score_df[[\"video_id\", \"time\", \"event\", \"score\"]]\n","score = event_detection_ap(solution[solution['video_id'].isin(video_ids)], valid_score_df, tolerances)\n","print(score)\n","\n","valid_score_df = validation_df[validation_df[\"angle\"] > thr]\n","valid_score_df = valid_score_df[valid_score_df[\"event\"] == \"challenge\"]\n","valid_score_df = valid_score_df[[\"video_id\", \"time\", \"event\", \"score\"]]\n","score = event_detection_ap(solution[solution['video_id'].isin(video_ids)], valid_score_df, tolerances)\n","print(score)"]},{"cell_type":"code","execution_count":66,"metadata":{"vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["0.03223948735637806\n","0.06040557533251865\n","0.003023944040893193\n","0.03328894269572236\n"]}],"source":["thr = 125\n","valid_score_df = validation_df[validation_df[\"angle\"] > thr]\n","valid_score_df = valid_score_df[[\"video_id\", \"time\", \"event\", \"score\"]]\n","score = event_detection_ap(solution[solution['video_id'].isin(video_ids)], valid_score_df, tolerances)\n","print(score)\n","\n","valid_score_df = validation_df[validation_df[\"angle\"] > thr]\n","valid_score_df = valid_score_df[valid_score_df[\"event\"] == \"play\"]\n","valid_score_df = valid_score_df[[\"video_id\", \"time\", \"event\", \"score\"]]\n","score = event_detection_ap(solution[solution['video_id'].isin(video_ids)], valid_score_df, tolerances)\n","print(score)\n","\n","valid_score_df = validation_df[validation_df[\"angle\"] > thr]\n","valid_score_df = valid_score_df[valid_score_df[\"event\"] == \"throwin\"]\n","valid_score_df = valid_score_df[[\"video_id\", \"time\", \"event\", \"score\"]]\n","score = event_detection_ap(solution[solution['video_id'].isin(video_ids)], valid_score_df, tolerances)\n","print(score)\n","\n","valid_score_df = validation_df[validation_df[\"angle\"] > thr]\n","valid_score_df = valid_score_df[valid_score_df[\"event\"] == \"challenge\"]\n","valid_score_df = valid_score_df[[\"video_id\", \"time\", \"event\", \"score\"]]\n","score = event_detection_ap(solution[solution['video_id'].isin(video_ids)], valid_score_df, tolerances)\n","print(score)"]},{"cell_type":"markdown","metadata":{},"source":["# max angle thr"]},{"cell_type":"code","execution_count":67,"metadata":{"vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["0.03863723652456046\n","0.0914409534127844\n","0.006215068186899172\n","0.018255687973997833\n"]}],"source":["thr = 125\n","valid_score_df = validation_df[validation_df[\"max_angle\"] > thr]\n","valid_score_df = valid_score_df[[\"video_id\", \"time\", \"event\", \"score\"]]\n","score = event_detection_ap(solution[solution['video_id'].isin(video_ids)], valid_score_df, tolerances)\n","print(score)\n","\n","valid_score_df = validation_df[validation_df[\"max_angle\"] > thr]\n","valid_score_df = valid_score_df[valid_score_df[\"event\"] == \"play\"]\n","valid_score_df = valid_score_df[[\"video_id\", \"time\", \"event\", \"score\"]]\n","score = event_detection_ap(solution[solution['video_id'].isin(video_ids)], valid_score_df, tolerances)\n","print(score)\n","\n","valid_score_df = validation_df[validation_df[\"max_angle\"] > thr]\n","valid_score_df = valid_score_df[valid_score_df[\"event\"] == \"throwin\"]\n","valid_score_df = valid_score_df[[\"video_id\", \"time\", \"event\", \"score\"]]\n","score = event_detection_ap(solution[solution['video_id'].isin(video_ids)], valid_score_df, tolerances)\n","print(score)\n","\n","valid_score_df = validation_df[validation_df[\"max_angle\"] > thr]\n","valid_score_df = valid_score_df[valid_score_df[\"event\"] == \"challenge\"]\n","valid_score_df = valid_score_df[[\"video_id\", \"time\", \"event\", \"score\"]]\n","score = event_detection_ap(solution[solution['video_id'].isin(video_ids)], valid_score_df, tolerances)\n","print(score)"]},{"cell_type":"code","execution_count":68,"metadata":{"vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["0.03852204250377017\n","0.08944824133244872\n","0.006376681278333521\n","0.01974120490052827\n"]}],"source":["thr = 150\n","valid_score_df = validation_df[validation_df[\"max_angle\"] > thr]\n","valid_score_df = valid_score_df[[\"video_id\", \"time\", \"event\", \"score\"]]\n","score = event_detection_ap(solution[solution['video_id'].isin(video_ids)], valid_score_df, tolerances)\n","print(score)\n","\n","valid_score_df = validation_df[validation_df[\"max_angle\"] > thr]\n","valid_score_df = valid_score_df[valid_score_df[\"event\"] == \"play\"]\n","valid_score_df = valid_score_df[[\"video_id\", \"time\", \"event\", \"score\"]]\n","score = event_detection_ap(solution[solution['video_id'].isin(video_ids)], valid_score_df, tolerances)\n","print(score)\n","\n","valid_score_df = validation_df[validation_df[\"max_angle\"] > thr]\n","valid_score_df = valid_score_df[valid_score_df[\"event\"] == \"throwin\"]\n","valid_score_df = valid_score_df[[\"video_id\", \"time\", \"event\", \"score\"]]\n","score = event_detection_ap(solution[solution['video_id'].isin(video_ids)], valid_score_df, tolerances)\n","print(score)\n","\n","valid_score_df = validation_df[validation_df[\"max_angle\"] > thr]\n","valid_score_df = valid_score_df[valid_score_df[\"event\"] == \"challenge\"]\n","valid_score_df = valid_score_df[[\"video_id\", \"time\", \"event\", \"score\"]]\n","score = event_detection_ap(solution[solution['video_id'].isin(video_ids)], valid_score_df, tolerances)\n","print(score)"]},{"cell_type":"code","execution_count":69,"metadata":{"vscode":{"languageId":"python"}},"outputs":[{"name":"stdout","output_type":"stream","text":["0.03728360683347955\n","0.0857215992369892\n","0.0056674123788217744\n","0.020461808884627675\n"]}],"source":["thr = 170\n","valid_score_df = validation_df[validation_df[\"max_angle\"] > thr]\n","valid_score_df = valid_score_df[[\"video_id\", \"time\", \"event\", \"score\"]]\n","score = event_detection_ap(solution[solution['video_id'].isin(video_ids)], valid_score_df, tolerances)\n","print(score)\n","\n","valid_score_df = validation_df[validation_df[\"max_angle\"] > thr]\n","valid_score_df = valid_score_df[valid_score_df[\"event\"] == \"play\"]\n","valid_score_df = valid_score_df[[\"video_id\", \"time\", \"event\", \"score\"]]\n","score = event_detection_ap(solution[solution['video_id'].isin(video_ids)], valid_score_df, tolerances)\n","print(score)\n","\n","valid_score_df = validation_df[validation_df[\"max_angle\"] > thr]\n","valid_score_df = valid_score_df[valid_score_df[\"event\"] == \"throwin\"]\n","valid_score_df = valid_score_df[[\"video_id\", \"time\", \"event\", \"score\"]]\n","score = event_detection_ap(solution[solution['video_id'].isin(video_ids)], valid_score_df, tolerances)\n","print(score)\n","\n","valid_score_df = validation_df[validation_df[\"max_angle\"] > thr]\n","valid_score_df = valid_score_df[valid_score_df[\"event\"] == \"challenge\"]\n","valid_score_df = valid_score_df[[\"video_id\", \"time\", \"event\", \"score\"]]\n","score = event_detection_ap(solution[solution['video_id'].isin(video_ids)], valid_score_df, tolerances)\n","print(score)"]},{"cell_type":"markdown","metadata":{},"source":["# angleのチェック"]},{"cell_type":"code","execution_count":70,"metadata":{"vscode":{"languageId":"python"}},"outputs":[{"data":{"text/plain":["<AxesSubplot:>"]},"execution_count":70,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["validation_df[\"angle\"].hist(bins=100)"]},{"cell_type":"code","execution_count":72,"metadata":{"vscode":{"languageId":"python"}},"outputs":[{"data":{"text/plain":["<AxesSubplot:>"]},"execution_count":72,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAATZUlEQVR4nO3df6zd9X3f8edruCQpbjCU6ArZrHZWLxMNWgtXwJQ2ui4dGNLFtEsjKlRMSmdNIx3ZmBpnUUeUHxLZ2mahalN5xarJWBxKU2GFZMRzuIv6B4SYEMyPUDvEaWw5eI0dp05oWqfv/XE+do6dc2187rnnB34+pKv7PZ/vj/O633t9Xuf7Pd9znKpCknRm+0ejDiBJGj3LQJJkGUiSLANJEpaBJAlYNOoA/brgggtq+fLlfa37ne98h3POOWewgRaAOQdvUrKac7AmJScsbNbt27f/dVW9pufMqprIr8suu6z69fDDD/e97jCZc/AmJas5B2tSclYtbFbgCzXHY6qniSRJloEkyTKQJGEZSJKwDCRJWAaSJCwDSRKWgSQJy0CSxAR/HIUknSmWr3/w2PTuO9+0IPfhkYEkyTKQJFkGkiQsA0kSloEkCctAkoRlIEnCMpAkYRlIkrAMJElYBpIkLANJEpaBJAnLQJLESyiDJBuT7E/yVNfY+Um2JtnZvp/XxpPkriS7kjyZ5NKudda25XcmWds1flmSHW2du5Jk0D+kJOnkXsqRwZ8Aq08YWw9sq6qVwLZ2G+BaYGX7Wgd8BDrlAdwBXAFcDtxxtEDaMv+ma70T70uStMBOWQZV9TngwAnDa4BNbXoTcH3X+D3V8QiwJMmFwDXA1qo6UFUHga3A6jbv1VX1SFUVcE/XtiRJQ9LvawZTVbWvTX8DmGrTS4Gvdy23p42dbHxPj3FJ0hDN+7+9rKpKUoMIcypJ1tE5/cTU1BSzs7N9befw4cN9rztM5hy8SclqzsGalJzQO+vtlxw5Nr1QP0e/ZfBCkgural871bO/je8FLupablkb2wvMnDA+28aX9Vi+p6raAGwAmJ6erpmZmbkWPanZ2Vn6XXeYzDl4k5LVnIM1KTmhd9abu/8P5BuPnzco/Z4m2gIcvSJoLfBA1/hN7aqiK4FD7XTSQ8DVSc5rLxxfDTzU5n07yZXtKqKburYlSRqSUx4ZJPkYnWf1FyTZQ+eqoDuB+5LcAnwNeGtb/FPAdcAu4LvA2wCq6kCS9wGPteXeW1VHX5T+d3SuWHoV8On2JUkaolOWQVX96hyzruqxbAG3zrGdjcDGHuNfAF5/qhySpIXjO5AlSZaBJMkykCRhGUiSsAwkSVgGkiQsA0kSloEkCctAkoRlIEnCMpAkYRlIkrAMJElYBpIkLANJEpaBJAnLQJKEZSBJwjKQJGEZSJKwDCRJWAaSJCwDSRKWgSQJy0CShGUgScIykCRhGUiSsAwkScyzDJL8hyRPJ3kqyceSvDLJiiSPJtmV5ONJzm7LvqLd3tXmL+/azrva+HNJrpnnzyRJOk19l0GSpcC/B6ar6vXAWcANwAeBD1XVTwIHgVvaKrcAB9v4h9pyJLm4rfdTwGrgD5Oc1W8uSdLpm+9pokXAq5IsAn4U2Af8PHB/m78JuL5Nr2m3afOvSpI2vrmqvldVXwV2AZfPM5ck6TSkqvpfObkN+ADwIvAZ4DbgkfbsnyQXAZ+uqtcneQpYXVV72ryvAFcA72nr/M82fndb5/4e97cOWAcwNTV12ebNm/vKffjwYRYvXtzXusNkzsGblKzmHKxJyQm9s+7Ye+jY9CVLz+1726tWrdpeVdO95i3qd6NJzqPzrH4F8C3gT+mc5lkwVbUB2AAwPT1dMzMzfW1ndnaWftcdJnMO3qRkNedgTUpO6J315vUPHpvefePx8wZlPqeJfgH4alX9v6r6e+ATwBuAJe20EcAyYG+b3gtcBNDmnwt8s3u8xzqSpCGYTxn8FXBlkh9t5/6vAp4BHgbe0pZZCzzQpre027T5n63OOaotwA3taqMVwErg8/PIJUk6TX2fJqqqR5PcDzwOHAG+SOcUzoPA5iTvb2N3t1XuBj6aZBdwgM4VRFTV00nuo1MkR4Bbq+r7/eaSJJ2+vssAoKruAO44Yfh5elwNVFV/C/zKHNv5AJ0XoiVJI+A7kCVJloEkyTKQJGEZSJKwDCRJWAaSJCwDSRKWgSQJy0CShGUgScIykCRhGUiSsAwkSVgGkiQsA0kSloEkCctAkoRlIEnCMpAkYRlIkrAMJElYBpIkLANJEpaBJAnLQJKEZSBJwjKQJGEZSJKwDCRJzLMMkixJcn+SLyd5Nsm/SHJ+kq1Jdrbv57Vlk+SuJLuSPJnk0q7trG3L70yydr4/lCTp9Mz3yODDwP+uqn8G/HPgWWA9sK2qVgLb2m2Aa4GV7Wsd8BGAJOcDdwBXAJcDdxwtEEnScPRdBknOBd4I3A1QVX9XVd8C1gCb2mKbgOvb9Brgnup4BFiS5ELgGmBrVR2oqoPAVmB1v7kkSacvVdXfislPAxuAZ+gcFWwHbgP2VtWStkyAg1W1JMkngTur6i/avG3AO4EZ4JVV9f42/tvAi1X1Oz3ucx2dowqmpqYu27x5c1/ZDx8+zOLFi/tad5jMOXiTktWcgzUpOaF31h17Dx2bvmTpuX1ve9WqVdurarrXvEV9b7Wz7qXAb1bVo0k+zA9OCQFQVZWkv7bpoao20Ckgpqena2Zmpq/tzM7O0u+6w2TOwZuUrOYcrEnJCb2z3rz+wWPTu288ft6gzOc1gz3Anqp6tN2+n045vNBO/9C+72/z9wIXda2/rI3NNS5JGpK+y6CqvgF8Pcnr2tBVdE4ZbQGOXhG0FnigTW8BbmpXFV0JHKqqfcBDwNVJzmsvHF/dxiRJQzKf00QAvwncm+Rs4HngbXQK5r4ktwBfA97alv0UcB2wC/huW5aqOpDkfcBjbbn3VtWBeeaSJJ2GeZVBVT0B9Hox4qoeyxZw6xzb2QhsnE8WSVL/fAeyJMkykCRZBpIkLANJEpaBJAnLQJKEZSBJwjKQJGEZSJKwDCRJWAaSJCwDSRKWgSQJy0CShGUgScIykCRhGUiSsAwkSVgGkiQsA0kSloEkCctAkoRlIEnCMpAkYRlIkoBFow4gSfphy9c/ONT788hAkmQZSJIGUAZJzkryxSSfbLdXJHk0ya4kH09ydht/Rbu9q81f3rWNd7Xx55JcM99MkqTTM4gjg9uAZ7tufxD4UFX9JHAQuKWN3wIcbOMfasuR5GLgBuCngNXAHyY5awC5JEkv0bzKIMky4E3AH7fbAX4euL8tsgm4vk2vabdp869qy68BNlfV96rqq8Au4PL55JIknZ75Hhn8d+C3gH9ot38c+FZVHWm39wBL2/RS4OsAbf6htvyx8R7rSJKGoO9LS5P8IrC/qrYnmRlYopPf5zpgHcDU1BSzs7N9befw4cN9rztM5hy8SclqzsGalJzwg6y3X3Kk5/yF+jnm8z6DNwBvTnId8Erg1cCHgSVJFrVn/8uAvW35vcBFwJ4ki4BzgW92jR/Vvc5xqmoDsAFgenq6ZmZm+go+OztLv+sOkzkHb1KymnOwJiUn/CDrzXO8z2D3jTMLcr99nyaqqndV1bKqWk7nBeDPVtWNwMPAW9pia4EH2vSWdps2/7NVVW38hna10QpgJfD5fnNJkk7fQrwD+Z3A5iTvB74I3N3G7wY+mmQXcIBOgVBVTye5D3gGOALcWlXfX4BckqQ5DKQMqmoWmG3Tz9PjaqCq+lvgV+ZY/wPABwaRRZJ0+nwHsiTJMpAkWQaSJCwDSRKWgSQJy0CShGUgScIykCRhGUiSsAwkSVgGkiQsA0kSloEkCctAkoRlIEnCMpAkYRlIkjhDy2DH3kMsX/8gy+f4D6cl6UxzRpaBJOl4loEkyTKQJFkGkjQ2lq9/8NhrmsNmGUiSLANJkmUgScIykCRhGUiSsAwkSVgGkiTmUQZJLkrycJJnkjyd5LY2fn6SrUl2tu/ntfEkuSvJriRPJrm0a1tr2/I7k6yd/48lSTod8zkyOALcXlUXA1cCtya5GFgPbKuqlcC2dhvgWmBl+1oHfAQ65QHcAVwBXA7ccbRAJEnD0XcZVNW+qnq8Tf8N8CywFFgDbGqLbQKub9NrgHuq4xFgSZILgWuArVV1oKoOAluB1f3mkiSdvlTV/DeSLAc+B7we+KuqWtLGAxysqiVJPgncWVV/0eZtA94JzACvrKr3t/HfBl6sqt/pcT/r6BxVMDU1ddnmzZv7yrv/wCFeeLEzfcnSc/vaxjAcPnyYxYsXjzrGKU1KTpicrOYcrEnJuWPvIaZexbHHp17m85i1atWq7VU13Wveor632iRZDPwZ8I6q+nbn8b+jqirJ/NvmB9vbAGwAmJ6erpmZmb628/v3PsDv7uj86Ltv7G8bwzA7O0u/P+MwTUpOmJys5hyscc55/OcQLeL2S44ce3zqZaEes+Z1NVGSH6FTBPdW1Sfa8Avt9A/t+/42vhe4qGv1ZW1srnFJ0pDM52qiAHcDz1bV73XN2gIcvSJoLfBA1/hN7aqiK4FDVbUPeAi4Osl57YXjq9uYJGlI5nOa6A3ArwE7kjzRxv4zcCdwX5JbgK8Bb23zPgVcB+wCvgu8DaCqDiR5H/BYW+69VXVgHrkkSaep7zJoLwRnjtlX9Vi+gFvn2NZGYGO/WSRJ8+M7kCVJloEkyTKQJGEZSJKwDCRJWAaSJAbwcRSSpNNz/EdQjAePDCRJHhlI0jCM49FAN48MJEmWgSTJMpAkYRlIkvAFZElaMOP+onE3jwwkSR4ZSNIgTdLRQDePDCRJloEkydNEkjRvk3pqqJtHBpIkjwwkqR8vh6OBbpaBJJ1E94P+7jvfNMIkC8sykKSX6OV2NNDN1wwkSR4ZSBK8vJ/1vxSWgaQz1pleAN0sA0kva8vXP8jtlxzhZh/4T8oykPSy4zP+02cZSBpLPqAP19iUQZLVwIeBs4A/rqo7RxxJUh98EJ9MY1EGSc4C/gD4l8Ae4LEkW6rqmdEmkxZerwfP2y85wswploG53wR1sgfk7nXm+8DtufiXj7EoA+ByYFdVPQ+QZDOwBljwMngp/8jmegfiQj8DGuQ/tIXMPUkPCJOU9aX8nvr5XfrMXb2kqkadgSRvAVZX1W+0278GXFFVbz9huXXAunbzdcBzfd7lBcBf97nuMJlz8CYlqzkHa1JywsJm/Ymqek2vGeNyZPCSVNUGYMN8t5PkC1U1PYBIC8qcgzcpWc05WJOSE0aXdVw+jmIvcFHX7WVtTJI0BONSBo8BK5OsSHI2cAOwZcSZJOmMMRaniarqSJK3Aw/RubR0Y1U9vYB3Oe9TTUNizsGblKzmHKxJyQkjyjoWLyBLkkZrXE4TSZJGyDKQJJ1ZZZBkdZLnkuxKsn7UeY5KclGSh5M8k+TpJLe18fck2ZvkifZ13aizAiTZnWRHy/SFNnZ+kq1Jdrbv54044+u69tsTSb6d5B3jsk+TbEyyP8lTXWM992E67mp/t08muXTEOf9bki+3LH+eZEkbX57kxa59+0cjzjnn7zrJu9r+fC7JNSPO+fGujLuTPNHGh7s/q+qM+KLzwvRXgNcCZwNfAi4eda6W7ULg0jb9Y8BfAhcD7wH+06jz9ci7G7jghLH/Cqxv0+uBD4465wm/+28APzEu+xR4I3Ap8NSp9iFwHfBpIMCVwKMjznk1sKhNf7Ar5/Lu5cZgf/b8Xbd/W18CXgGsaI8LZ40q5wnzfxf4L6PYn2fSkcGxj7yoqr8Djn7kxchV1b6qerxN/w3wLLB0tKlO2xpgU5veBFw/uig/5CrgK1X1tVEHOaqqPgccOGF4rn24BrinOh4BliS5cFQ5q+ozVXWk3XyEzvuCRmqO/TmXNcDmqvpeVX0V2EXn8WHBnSxnkgBvBT42jCwnOpPKYCnw9a7bexjDB9wky4GfAR5tQ29vh+MbR33qpUsBn0myvX1ECMBUVe1r098ApkYTracbOP4f2DjuU5h7H47z3+6v0zlqOWpFki8m+b9Jfm5Uobr0+l2P6/78OeCFqtrZNTa0/XkmlcHYS7IY+DPgHVX1beAjwD8BfhrYR+cQchz8bFVdClwL3Jrkjd0zq3OMOxbXLLc3Mb4Z+NM2NK779DjjtA/nkuTdwBHg3ja0D/jHVfUzwH8E/leSV48qHxPyu+7yqxz/pGWo+/NMKoOx/siLJD9CpwjurapPAFTVC1X1/ar6B+B/MKRD2VOpqr3t+37gz+nkeuHoqYv2ff/oEh7nWuDxqnoBxnefNnPtw7H7201yM/CLwI2tuGinXb7ZprfTORf/T0eV8SS/63Hcn4uAXwY+fnRs2PvzTCqDsf3Ii3au8G7g2ar6va7x7vPCvwQ8deK6w5bknCQ/dnSazouJT9HZl2vbYmuBB0aT8Icc92xrHPdpl7n24RbgpnZV0ZXAoa7TSUOXzn9E9VvAm6vqu13jr0nn/yYhyWuBlcDzo0l50t/1FuCGJK9IsoJOzs8PO98JfgH4clXtOTow9P05rFeqx+GLzlUZf0mnYd896jxduX6WzimBJ4En2td1wEeBHW18C3DhGGR9LZ0rMb4EPH10PwI/DmwDdgL/Bzh/DLKeA3wTOLdrbCz2KZ2C2gf8PZ1z1rfMtQ/pXEX0B+3vdgcwPeKcu+iccz/6t/pHbdl/3f4mngAeB/7ViHPO+bsG3t3253PAtaPM2cb/BPi3Jyw71P3px1FIks6o00SSpDlYBpIky0CSZBlIkrAMJElYBpIkLANJEvD/AfrdzlM/Q+76AAAAAElFTkSuQmCC","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["validation_df[\"max_angle\"].hist(bins=100)"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"python"}},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":4}
